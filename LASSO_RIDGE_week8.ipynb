{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEAD_PATH = './'\n",
    "DATA_PATH = HEAD_PATH + \"data/stocks/\"\n",
    "SAVE_PATH = HEAD_PATH + \"ckpt/\"    # most of signal timeseries is here\n",
    "TEMP_PATH = SAVE_PATH + \"tmp pkl/\"\n",
    "OUTPUT_PATH = HEAD_PATH + 'output'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1 toc-item\"><a href=\"#Functions-to-be-overwritten\" data-toc-modified-id=\"Functions-to-be-overwritten-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Functions to be overwritten</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- in our original agenda this week we try different covariance estimation method\n",
    "- but I think we'd better go directly to regression model\n",
    "- then we can save some time for further more complicate machine learning models\n",
    "\n",
    "\n",
    "- this week we focus on the most simple linear regression without regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'stock_stats' from '/Users/junsu/Dropbox/workspace/stock_new/stock_stats.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from stock_helper import *\n",
    "from stock_stats import *\n",
    "from product_info import *\n",
    "from imp import reload  \n",
    "import stock_helper\n",
    "import stock_stats\n",
    "#TODL: stocker_helper define parLapply, to be explict instead of implicit\n",
    "reload(stock_helper)\n",
    "reload(stock_stats)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions to be overwritten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## parallel generate the distribution of a signal\n",
    "def par_get_all_signal(signal_name, file_list, product, period, SAVE_PATH=\"e:/intern\"):\n",
    "    \"\"\"\n",
    "    Our new functions that overwrite the stocker_helper\n",
    "    \"\"\"\n",
    "    n_files = len(file_list)\n",
    "    all_signal = np.array([])\n",
    "    for file in file_list:\n",
    "        S = load(SAVE_PATH+\"/tmp pkl/\"+product+\"/\"+signal_name+\"/\"+file) ## signal\n",
    "#         good = load(SAVE_PATH+\"/good pkl/\"+product+\"/\"+file) ## good singal\n",
    "#         signal = S[good]\n",
    "        signal = S\n",
    "        moving_average(signal,period)\n",
    "        chosen = (np.arange(len(signal))+1) % period==0\n",
    "        all_signal = np.concatenate((all_signal, signal[chosen]), axis=0)\n",
    "    save(all_signal, SAVE_PATH+\"/all signal/\"+product+\".\"+signal_name+\".pkl\")\n",
    "\n",
    "    \n",
    "# calc pnl given a signal\n",
    "def get_signal_pnl(file, product, signal_name, thre_mat, reverse=1,  buy_tranct=1.5e-4, sell_tranct=11.5e-4,\n",
    "                   max_spread=0.011,\n",
    "                   HEAD_PATH=HEAD_PATH, SAVE_PATH=SAVE_PATH, atr_filter=0):\n",
    "    ## load data\n",
    "    data = load(DATA_PATH+product+\"/\"+file)\n",
    "    S = load(SAVE_PATH+\"/tmp pkl/\"+product+\"/\"+signal_name+\"/\"+file)\n",
    "    pred = S*reverse\n",
    "    atr = load(SAVE_PATH+\"/tmp pkl/\"+product+\"/\"+\"atr.4096\"+\"/\"+file)\n",
    "    #n_bar = len(data)\n",
    "    \n",
    "    ## load signal\n",
    "    \n",
    "    ## we don't know the signal is positive correlated or negative correlated  \n",
    "    #n_thre = len(thre_mat)\n",
    "    date = np.array([x[0:10] for x in data[\"date.time\"]])\n",
    "    next_date = np.append(date[1:],'1')\n",
    "    end_day = date!=next_date\n",
    "    count = 0;\n",
    "    n_day = sum(end_day)\n",
    "    n_thre = np.shape(thre_mat)[0]\n",
    "    all_pnl = np.zeros((n_day, n_thre))\n",
    "    result = pd.DataFrame(data=OrderedDict([(\"open\", thre_mat[\"open\"].values), (\"close\", thre_mat[\"close\"].values),\n",
    "                               (\"num\", 0), (\"avg.ret\", 0), (\"ret\", 0)]), \n",
    "                          index=thre_mat.index)\n",
    "\n",
    "    cur_spread = data[\"ask1\"]-data[\"bid1\"]\n",
    "    for thre in thre_mat.iterrows():\n",
    "        count = count+1\n",
    "        buy = pred>thre[1][\"open\"]\n",
    "        sell = pred<-thre[1][\"open\"]\n",
    "        signal = pd.Series(data=0, index=data.index)\n",
    "        position = signal.copy()\n",
    "        signal[buy] = 1\n",
    "        signal[sell] = -1\n",
    "        signal[atr<atr_filter]=0\n",
    "        scratch = -thre[1][\"close\"]\n",
    "        position_pos = pd.Series(data=np.nan, index=data.index)\n",
    "        position_pos.iloc[0] = 0\n",
    "        position_pos[(signal==1) & (data[\"next.ask\"]>0) & (data[\"next.bid\"]>0) & (cur_spread<max_spread)] = 1\n",
    "        position_pos[(pred< -scratch) & (data[\"next.bid\"]>0) & (cur_spread<max_spread)] = 0\n",
    "        position_pos.ffill(inplace=True)\n",
    "        pre_pos = position_pos.shift(1)\n",
    "        notional_position_pos = pd.Series(data=0, index=data.index)\n",
    "        notional_position_pos[position_pos==1] = 1\n",
    "        notional_position_pos[(position_pos==1) & (pre_pos==1)] = np.nan\n",
    "        notional_position_pos[(notional_position_pos==1)] = 1/data[\"next.ask\"][(notional_position_pos==1)]\n",
    "        notional_position_pos.ffill(inplace=True)\n",
    "        position_neg = pd.Series(data=np.nan, index=data.index)\n",
    "        position_neg.iloc[0] = 0\n",
    "        position_neg[(signal==-1) & (data[\"next.ask\"]>0) & (data[\"next.bid\"]>0) & (cur_spread<max_spread)] = -1\n",
    "        position_neg[(pred> scratch) & (data[\"next.ask\"]>0) & (cur_spread<max_spread)] = 0\n",
    "        position_neg.ffill(inplace=True)\n",
    "        pre_neg = position_neg.shift(1)\n",
    "        notional_position_neg = pd.Series(data=0, index=data.index)\n",
    "        notional_position_neg[position_neg==-1] = -1\n",
    "        notional_position_neg[(position_neg==-1) & (pre_neg==-1)] = np.nan\n",
    "        notional_position_neg[(notional_position_neg==-1)] = -1/data[\"next.bid\"][(notional_position_neg==-1)]\n",
    "        notional_position_neg.ffill(inplace=True)\n",
    "        position = position_pos + position_neg\n",
    "        notional_position = notional_position_pos+notional_position_neg\n",
    "        #position[n_bar-1] = 0\n",
    "        position.iloc[0] = 0\n",
    "        position.iloc[-2:] = 0\n",
    "        notional_position.iloc[0] = 0\n",
    "        notional_position.iloc[-2:] = 0\n",
    "        #change_pos = position - position.shift(1)\n",
    "        #notional_change_pos = notional_position-notional_position.shift(1)\n",
    "        change_pos = notional_position-notional_position.shift(1)\n",
    "        change_pos.iloc[0] = 0\n",
    "        #notional_change_pos.iloc[0] = 0\n",
    "        change_base = pd.Series(data=0, index=data.index)\n",
    "        change_buy = change_pos>0\n",
    "        change_sell = change_pos<0\n",
    "        change_base[change_buy] = data[\"next.ask\"][change_buy]*(1+buy_tranct)*data[\"adjust\"]\n",
    "        change_base[change_sell] = data[\"next.bid\"][change_sell]*(1-sell_tranct)*data[\"adjust\"]\n",
    "        raw_pnl = -(change_base*change_pos).cumsum()+notional_position*data[\"wpr\"]\n",
    "        final_pnl = -sum(change_base*change_pos) ## total pnl, there is a negative sign, because selling get money and buying pay money\n",
    "        turnover = sum(change_base*abs(change_pos))\n",
    "        num = sum((position!=0) & (change_pos!=0)) ## number of trades\n",
    "        hld_period = sum(position!=0)   ## holding period\n",
    "        daily_pnl = raw_pnl[end_day].reset_index(drop=True)\n",
    "        pnl = np.append(daily_pnl[0], np.diff(daily_pnl))\n",
    "        all_pnl[:,thre[0]] = pnl\n",
    "        if (num==0):\n",
    "            result.loc[thre[0], (\"num\",\"avg.ret\",\"ret\")] = (0,0,0)\n",
    "        else:\n",
    "            result.loc[thre[0],(\"num\", \"avg.ret\", \"ret\", )] = (num, final_pnl/num, final_pnl)\n",
    "    return OrderedDict([(\"all.pnl\", all_pnl), (\"result\", result), (\"date\", date[end_day])])\n",
    "\n",
    "    \n",
    "from collections import OrderedDict\n",
    "def get_signal_stat(signal_name, thre_mat, product, all_dates, CORE_NUM, split_str=\"2018\", reverse=1, \n",
    "                     atr_filter=0, HEAD_PATH=\"d:/intern\", SAVE_PATH=\"d:/intern\"):\n",
    "    train_sample = all_dates<split_str ## training samples\n",
    "    test_sample = all_dates>split_str ## testing samples\n",
    "    with dask.config.set(scheduler='processes', num_workers=CORE_NUM):\n",
    "        f_par = functools.partial(get_signal_pnl, product=product, signal_name=signal_name, thre_mat=thre_mat,\n",
    "                                 reverse=1,\n",
    "                                HEAD_PATH=HEAD_PATH, SAVE_PATH=SAVE_PATH,atr_filter=atr_filter)\n",
    "        train_result = compute([delayed(f_par)(file) for file in all_dates[train_sample]])[0] ## get training result\n",
    "    train_stat = get_hft_summary(train_result, thre_mat) ## get training result statistics\n",
    "    with dask.config.set(scheduler='processes', num_workers=CORE_NUM):\n",
    "        f_par = functools.partial(get_signal_pnl, product=product, signal_name=signal_name, thre_mat=thre_mat,\n",
    "                                 reverse=1,\n",
    "                                HEAD_PATH=HEAD_PATH, SAVE_PATH=SAVE_PATH,atr_filter=atr_filter)\n",
    "        test_result = compute([delayed(f_par)(file) for file in all_dates[test_sample]])[0] ## get testing result\n",
    "    test_stat = get_hft_summary(test_result, thre_mat) ## get testing result statistics\n",
    "    return OrderedDict([(\"train.stat\", train_stat), (\"test.stat\", test_stat)])\n",
    "\n",
    "    \n",
    "def evaluate_signal(signal, all_dates, product, min_pnl, min_num, \n",
    "                    CORE_NUM, HEAD_PATH=\"d:/intern\", SIGNAL_PATH=\"d:/intern\", period=4096, split_str=\"2018\", \n",
    "                    atr_filter=0, save_path=\"signal result\",reverse=0):\n",
    "    signal_name = signal+\".\"+str(period) ## signal name, with period\n",
    "    all_signal = load(SIGNAL_PATH+\"/all signal/\"+product+\".\"+signal_name+\".pkl\") ## get the distribution of the signal\n",
    "    open_list = np.quantile(abs(all_signal), np.append(np.arange(0.991,0.999,0.001),np.arange(0.9991,0.9999,0.0001))) ## open threshold\n",
    "    thre_list = []\n",
    "    for cartesian in itertools.product(open_list, np.array([0.2, 0.4, 0.6, 0.8, 1.0])): ## close threshold\n",
    "        thre_list.append((cartesian[0], -cartesian[0] * cartesian[1]))\n",
    "    thre_list = np.array(thre_list)\n",
    "    thre_mat = pd.DataFrame(data=OrderedDict([(\"open\", thre_list[:, 0]), (\"close\", thre_list[:, 1])])) ## threshold matrix\n",
    "    \n",
    "    if reverse>=0: ## trending signal\n",
    "        print(\"reverse=1\")\n",
    "        trend_signal_stat = get_signal_stat(signal_name, thre_mat, product, all_dates, CORE_NUM, split_str=split_str, reverse=1, \n",
    "                                    atr_filter=atr_filter, HEAD_PATH=HEAD_PATH, SAVE_PATH=SIGNAL_PATH)\n",
    "    if reverse<=0: ## reversal signal\n",
    "        print(\"reverse=-1\")\n",
    "        reverse_signal_stat = get_signal_stat(signal_name, thre_mat, product, all_dates, CORE_NUM, split_str=split_str, reverse=-1,\n",
    "                                            atr_filter=atr_filter, HEAD_PATH=HEAD_PATH, SAVE_PATH=SIGNAL_PATH)\n",
    "    if reverse==0: ## both trending and reversal\n",
    "        stat_result = OrderedDict([(\"trend.signal.stat\", trend_signal_stat), (\"reverse.signal.stat\", reverse_signal_stat)])    \n",
    "        save(stat_result, HEAD_PATH+\"/\"+save_path+\"/\"+product+\".\"+signal_name+\".pkl\")\n",
    "    elif reverse==1: ## just trend\n",
    "        save(trend_signal_stat, HEAD_PATH+\"/\"+save_path+\"/\"+product+\".\"+signal_name+\".trend.pkl\")\n",
    "    elif reverse==-1: ## just reversal\n",
    "        save(reverse_signal_stat, HEAD_PATH+\"/\"+save_path+\"/\"+product+\".\"+signal_name+\".reverse.pkl\")\n",
    "        \n",
    "# summarize pnl over thresholds\n",
    "def get_hft_summary(result, thre_mat):\n",
    "    n_thre = np.shape(thre_mat)[0]\n",
    "    all_pnl = np.zeros((0,n_thre))\n",
    "    all_dates = np.array([])\n",
    "    for i in range(len(result)):\n",
    "        all_pnl =  np.concatenate((all_pnl,result[i][\"all.pnl\"]),axis=0)\n",
    "        all_dates = np.append(all_dates, result[i][\"date\"])\n",
    "    stat = result[0][\"result\"].iloc[:,2:]\n",
    "    for i in range(1,len(result)):\n",
    "        stat = stat+result[i][\"result\"].iloc[:,2:]\n",
    "    stat[\"avg.ret\"]=stat[\"ret\"]/stat[\"num\"]\n",
    "    \n",
    "    total_ret = all_pnl.sum(0)\n",
    "    total_sharpe = np.zeros(n_thre)\n",
    "    total_drawdown = np.zeros(n_thre)\n",
    "    total_max_drawdown = np.zeros(n_thre)\n",
    "    for i in range(n_thre):\n",
    "        total_sharpe[i] = sharpe(all_pnl[:,i])\n",
    "        total_drawdown[i] = drawdown(all_pnl[:,i])\n",
    "        total_max_drawdown[i] = max_drawdown(all_pnl[:,i])\n",
    "    final_result = pd.DataFrame(data=OrderedDict([(\"open\", thre_mat[\"open\"]), (\"close\", thre_mat[\"close\"]), (\"num\", stat[\"num\"]),\n",
    "                                                  (\"avg.ret\", stat[\"avg.ret\"]), (\"total.ret\",total_ret), (\"sharpe\", total_sharpe),\n",
    "                                                  (\"drawdown\", total_drawdown), (\"max.drawdown\", total_max_drawdown),\n",
    "                                                 (\"mar\", total_ret/total_max_drawdown)]), \n",
    "                                index=thre_mat.index)\n",
    "    return OrderedDict([(\"final.result\", final_result), (\"daily.pnl\", all_pnl), (\"date\", all_dates)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function par_get_all_signal in module __main__:\n",
      "\n",
      "par_get_all_signal(signal_name, file_list, product, period, SAVE_PATH='e:/intern')\n",
      "    Our new functions that overwrite the stocker_helper\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(par_get_all_signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_platform():\n",
    "    import sys\n",
    "    platforms = {\n",
    "        'linux1' : 'Linux',\n",
    "        'linux2' : 'Linux',\n",
    "        'darwin' : 'OS X',\n",
    "        'win32' : 'Windows'\n",
    "    }\n",
    "    if sys.platform not in platforms:\n",
    "        return sys.platform\n",
    "    \n",
    "    return platforms[sys.platform]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if get_platform() != 'OS X':\n",
    "    CORE_NUM = int(os.environ['NUMBER_OF_PROCESSORS'])\n",
    "else:\n",
    "    import multiprocessing\n",
    "    CORE_NUM = multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    " \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_list = [\"600519\", \"000858\", \"000568\", \"600809\", \"002304\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "period = 4096"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "all_dates = os.listdir(DATA_PATH + product_list[0])\n",
    "all_dates.sort()\n",
    "all_dates = np.array(all_dates)\n",
    "n_days = len(all_dates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "from dask import compute, delayed\n",
    "import sklearn.preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(HEAD_PATH+\"/all signal\", exist_ok=True)\n",
    "dire_signal_list = [\"nr\", \"dbook\", \"range.pos\", \"price.osci\", \"ma.dif.10\", \"kdj.k\", \"kdj.j\"]\n",
    "range_signal_list = [\"\", \"range\", \"std\", \"trend.index\"]\n",
    "\n",
    "####### Refactor the below code by product #########\n",
    "# sloppy code-1\n",
    "all_signal_list = np.array([])\n",
    "for range_signal in range_signal_list:\n",
    "    for dire_signal in dire_signal_list:\n",
    "        if len(range_signal)==0:\n",
    "            signal_name = dire_signal\n",
    "        else:\n",
    "            signal_name = dire_signal+\".\"+range_signal\n",
    "        all_signal_list = np.append(all_signal_list,signal_name)\n",
    "\n",
    "## clean code-1\n",
    "#from itertools import product\n",
    "\n",
    "#def signal_product(signal_list1, signa_list2):\n",
    "#    return list(map(lambda x: \".\".join(x), list( product(signal_list1, signal_list2))))\n",
    "\n",
    "#all_signal_list = signal_product(dire_signal_list, range_signal_list)\n",
    "#####################################################\n",
    "        \n",
    "\n",
    "# append .4096, add 3 more signal\n",
    "signal_list = [signal+\".4096\" for signal in all_signal_list]\n",
    "# you have a bug here?? the ret.4096, ret.4096.001, ret.4096.002 is added by not assgiend to signal_list?\n",
    "np.append(signal_list, [\"ret.4096\", \"ret.4096.001\", \"ret.4096.002\"])\n",
    "n_signal = len(signal_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- let's begin with week 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import lasso_path, LassoCV, RidgeCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#y_signal = \"ret.\"+str(period)+\".002\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "product = product_list[0]\n",
    "train_mat = load(SAVE_PATH+\"/train test mat/\"+product+\".train.mat.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- it seems the result is too bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600519\n",
      "[-0.  0. -0. -0. -0. -0. -0. -0.  0. -0. -0. -0. -0. -0. -0. -0. -0. -0.\n",
      " -0. -0. -0. -0. -0. -0. -0. -0. -0. -0.]\n",
      "000858\n",
      "[-0.         -0.005781   -0.         -0.         -0.00643598  0.00046193\n",
      "  0.          0.         -0.          0.         -0.          0.\n",
      "  0.0002564   0.00030326 -0.         -0.         -0.         -0.00815474\n",
      " -0.          0.         -0.         -0.         -0.0012126  -0.\n",
      " -0.00040279 -0.          0.          0.        ]\n",
      "000568\n",
      "[-0.         -0.          0.         -0.00023886 -0.05013818  0.\n",
      " -0.          0.         -0.         -0.         -0.          0.\n",
      "  0.         -0.          0.02754591 -0.00589875  0.00791138 -0.\n",
      "  0.          0.00080328  0.         -0.          0.          0.\n",
      " -0.         -0.          0.         -0.        ]\n",
      "600809\n",
      "[-0.          0.         -0.         -0.         -0.          0.\n",
      "  0.          0.         -0.          0.          0.          0.\n",
      "  0.00011908  0.          0.         -0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.        ]\n",
      "002304\n",
      "[-0.          0.         -0.         -0.00066911 -0.00512298  0.\n",
      " -0.00045352  0.          0.         -0.         -0.          0.\n",
      "  0.         -0.          0.          0.          0.         -0.\n",
      "  0.          0.         -0.         -0.          0.         -0.\n",
      " -0.         -0.          0.         -0.        ]\n"
     ]
    }
   ],
   "source": [
    "coef_list=dict([])\n",
    "y_signal = \"ret.\"+str(period)+\".002\"\n",
    "for product in product_list:\n",
    "    train_mat = load(SAVE_PATH+\"/train test mat/\"+product+\".train.mat.pkl\")\n",
    "    x_train = train_mat.iloc[:, :n_signal].values\n",
    "    y_train = train_mat.loc[:, y_signal].values\n",
    "    scaler =  StandardScaler(copy=True, with_mean=True, with_std=True) # normalize\n",
    "    scaler.fit(x_train)\n",
    "    x_std = np.sqrt(scaler.var_)\n",
    "    x_train_normal = scaler.transform(x_train)\n",
    "    y_std = np.std(y_train)\n",
    "    model = LassoCV(n_alphas=100, fit_intercept=False, cv=5, max_iter=10000).fit(x_train_normal, y_train/y_std)\n",
    "    coef = model.coef_/x_std*y_std\n",
    "    print(product)\n",
    "    print(coef)\n",
    "    coef_list[product] = coef\n",
    "\n",
    "# 600276\n",
    "# [-0.          0.00344643 -0.         -0.         -0.         -0.\n",
    "#  -0.          0.          0.          0.          0.         -0.\n",
    "#  -0.          0.         -0.          0.00301317 -0.         -0.\n",
    "#  -0.         -0.         -0.         -0.          0.         -0.\n",
    "#  -0.         -0.         -0.00105632 -0.00026428]\n",
    "# 000538\n",
    "# [ 0.01266931  0.         -0.          0.          0.          0.\n",
    "#  -0.00076245  0.          0.         -0.          0.          0.\n",
    "#   0.         -0.          0.          0.0016023  -0.          0.\n",
    "#  -0.          0.         -0.00102048  0.          0.         -0.\n",
    "#   0.          0.          0.00033424 -0.        ]\n",
    "# 600332\n",
    "# [-3.0919854e-17  0.0000000e+00 -0.0000000e+00 -0.0000000e+00\n",
    "#  -0.0000000e+00 -0.0000000e+00 -0.0000000e+00 -0.0000000e+00\n",
    "#   0.0000000e+00 -0.0000000e+00 -0.0000000e+00 -0.0000000e+00\n",
    "#  -0.0000000e+00 -0.0000000e+00 -0.0000000e+00  0.0000000e+00\n",
    "#  -0.0000000e+00 -0.0000000e+00 -0.0000000e+00 -0.0000000e+00\n",
    "#  -0.0000000e+00 -0.0000000e+00  0.0000000e+00 -0.0000000e+00\n",
    "#  -0.0000000e+00 -0.0000000e+00 -0.0000000e+00 -0.0000000e+00]\n",
    "# 600436\n",
    "# [-0.00000000e+00  0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
    "#  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
    "#   0.00000000e+00 -0.00000000e+00 -0.00000000e+00  0.00000000e+00\n",
    "#  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00  0.00000000e+00\n",
    "#  -0.00000000e+00 -0.00000000e+00  0.00000000e+00 -0.00000000e+00\n",
    "#  -0.00000000e+00 -0.00000000e+00  0.00000000e+00 -0.00000000e+00\n",
    "#  -9.08294731e-19 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00]\n",
    "# 600535\n",
    "# [ 0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
    "#  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00  0.00000000e+00\n",
    "#   0.00000000e+00 -0.00000000e+00 -0.00000000e+00  0.00000000e+00\n",
    "#  -0.00000000e+00 -0.00000000e+00  9.37426231e-18 -0.00000000e+00\n",
    "#   0.00000000e+00 -0.00000000e+00  0.00000000e+00 -0.00000000e+00\n",
    "#  -0.00000000e+00 -0.00000000e+00  0.00000000e+00 -0.00000000e+00\n",
    "#  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "save(coef_list, SAVE_PATH+\"/wine.coef.ret.4096.002.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600519\n",
      "[ 0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00 -8.45903437e-04 -5.09172095e-06  0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00  0.00000000e+00 -0.00000000e+00\n",
      "  0.00000000e+00 -0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  9.04792620e-02 -0.00000000e+00 -0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      "000858\n",
      "[ 0.         -0.006704    0.         -0.         -0.06637936  0.00183745\n",
      "  0.          0.00623261 -0.         -0.         -0.          0.\n",
      "  0.          0.          0.         -0.00558503 -0.         -0.00223805\n",
      " -0.          0.          0.          0.         -0.         -0.00472675\n",
      " -0.         -0.02579366  0.         -0.        ]\n",
      "000568\n",
      "[-0.         -0.          0.         -0.         -0.01052026  0.\n",
      " -0.         -0.         -0.         -0.         -0.         -0.00316935\n",
      " -0.         -0.00019701 -0.         -0.00067919 -0.         -0.\n",
      " -0.00235397 -0.         -0.         -0.         -0.          0.\n",
      " -0.         -0.          0.         -0.        ]\n",
      "600809\n",
      "[ 0. -0. -0. -0. -0.  0. -0.  0. -0. -0. -0. -0. -0. -0.  0. -0. -0. -0.\n",
      " -0. -0. -0.  0. -0.  0.  0.  0.  0.  0.]\n",
      "002304\n",
      "[-0.03718111  0.         -0.         -0.         -0.03664855  0.00117475\n",
      " -0.         -0.         -0.         -0.         -0.         -0.\n",
      "  0.         -0.         -0.         -0.00012538 -0.         -0.\n",
      " -0.          0.         -0.         -0.          0.         -0.\n",
      " -0.         -0.          0.         -0.        ]\n"
     ]
    }
   ],
   "source": [
    "coef_list=dict([])\n",
    "y_signal = \"ret.\"+str(period)+\".004\"\n",
    "for product in product_list:\n",
    "    train_mat = load(SAVE_PATH+\"/train test mat/\"+product+\".train.mat.pkl\")\n",
    "    x_train = train_mat.iloc[:, :n_signal].values\n",
    "    y_train = train_mat.loc[:, y_signal].values\n",
    "    scaler =  StandardScaler(copy=True, with_mean=True, with_std=True)\n",
    "    scaler.fit(x_train)\n",
    "    x_std = np.sqrt(scaler.var_)\n",
    "    x_train_normal = scaler.transform(x_train)\n",
    "    y_std = np.std(y_train)\n",
    "    model = LassoCV(n_alphas=100, fit_intercept=False, cv=5, max_iter=10000).fit(x_train_normal, y_train/y_std)\n",
    "    coef = model.coef_/x_std*y_std\n",
    "    print(product)\n",
    "    print(coef)\n",
    "    coef_list[product] = coef\n",
    "    \n",
    "# 600519\n",
    "# [ 0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
    "#  -0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
    "#   0.00000000e+00 -8.45903437e-04 -5.09172095e-06  0.00000000e+00\n",
    "#  -0.00000000e+00 -0.00000000e+00  0.00000000e+00 -0.00000000e+00\n",
    "#   0.00000000e+00 -0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
    "#   0.00000000e+00  9.04792620e-02 -0.00000000e+00 -0.00000000e+00\n",
    "#   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
    "# 000858\n",
    "# [ 0.         -0.006704    0.         -0.         -0.06637936  0.00183745\n",
    "#   0.          0.00623261 -0.         -0.         -0.          0.\n",
    "#   0.          0.          0.         -0.00558503 -0.         -0.00223805\n",
    "#  -0.          0.          0.          0.         -0.         -0.00472675\n",
    "#  -0.         -0.02579366  0.         -0.        ]\n",
    "# 000568\n",
    "# [-0.         -0.          0.         -0.         -0.01052026  0.\n",
    "#  -0.         -0.         -0.         -0.         -0.         -0.00316935\n",
    "#  -0.         -0.00019701 -0.         -0.00067919 -0.         -0.\n",
    "#  -0.00235397 -0.         -0.         -0.         -0.          0.\n",
    "#  -0.         -0.          0.         -0.        ]\n",
    "# 600809\n",
    "# [ 0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
    "#  -0.00000000e+00  0.00000000e+00 -0.00000000e+00  0.00000000e+00\n",
    "#  -2.02811516e-18 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
    "#  -0.00000000e+00 -0.00000000e+00  0.00000000e+00 -0.00000000e+00\n",
    "#  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
    "#  -0.00000000e+00  0.00000000e+00 -0.00000000e+00  0.00000000e+00\n",
    "#   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
    "# 002304\n",
    "# [-0.03718111  0.         -0.         -0.         -0.03664855  0.00117475\n",
    "#  -0.         -0.         -0.         -0.         -0.         -0.\n",
    "#   0.         -0.         -0.         -0.00012538 -0.         -0.\n",
    "#  -0.          0.         -0.         -0.          0.         -0.\n",
    "#  -0.         -0.          0.         -0.        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "save(coef_list, SAVE_PATH+\"/wine.coef.ret.4096.004.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- we can see that the result is not good"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- it's still not good. So we cannot use lasso model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def par_get_signal_mat(file_name, product, signal_list, HEAD_PATH, SAVE_PATH):\n",
    "    #data = load(HEAD_PATH+\"/stock pkl/\"+product+\"/\"+file_name)\n",
    "    data = load(HEAD_PATH+\"data/stocks/\"+product+\"/\"+file_name)\n",
    "\n",
    "    signal_mat = functools.reduce(functools.partial(get_signal_mat, product=product, file_name=file_name, HEAD_PATH=SAVE_PATH), signal_list, None)\n",
    "    save(signal_mat, SAVE_PATH+\"/signal mat pkl/\"+product+\"/\"+file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def par_get_daily_pred(file_name, product, coef, strat, HEAD_PATH):\n",
    "    signal_mat = load(HEAD_PATH+\"/signal mat pkl/\"+product+\"/\"+file_name)\n",
    "    S = np.dot(signal_mat.transpose(),coef)\n",
    "    save(S, HEAD_PATH+\"/tmp pkl/\"+product+\"/\"+strat+\"/\"+file_name)      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- now let's try lasso regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "strat = \"lasso.004.\"+str(period)\n",
    "for product in product_list:\n",
    "    os.makedirs(SAVE_PATH+\"/tmp pkl/\"+product+\"/\"+strat, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_list = load(SAVE_PATH+\"/wine.coef.ret.4096.004.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for product in product_list:\n",
    "    os.makedirs(SAVE_PATH+\"/tmp pkl/\"+product+\"/\"+strat, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(SAVE_PATH+\"/signal mat pkl\", exist_ok=True)\n",
    "for product in product_list:\n",
    "    os.makedirs(SAVE_PATH+\"/signal mat pkl/\"+product, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(abs(coef_list[\"600809\"])>1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600519\n",
      "000858\n",
      "000568\n",
      "600809\n",
      "002304\n",
      "CPU times: user 276 ms, sys: 564 ms, total: 840 ms\n",
      "Wall time: 3min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for product in product_list:\n",
    "    print(product)\n",
    "    parLapply(CORE_NUM, all_dates, par_get_signal_mat, product=product, signal_list=signal_list, HEAD_PATH=HEAD_PATH, SAVE_PATH=SAVE_PATH)\n",
    "    \n",
    "# 600519\n",
    "# 000858\n",
    "# 000568\n",
    "# 600809\n",
    "# 002304\n",
    "# Wall time: 3min 38s\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600519\n",
      "000858\n",
      "000568\n",
      "002304\n",
      "CPU times: user 198 ms, sys: 292 ms, total: 490 ms\n",
      "Wall time: 32.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for product in product_list:\n",
    "    if (np.sum(abs(coef_list[product])>1e-8)>-0):\n",
    "        print(product)\n",
    "        coef = coef_list[product]\n",
    "        parLapply(CORE_NUM, all_dates, par_get_daily_pred, \n",
    "                  product=product, coef=coef, strat=strat, HEAD_PATH=SAVE_PATH)\n",
    "\n",
    "# 600519\n",
    "# 000858\n",
    "# 000568\n",
    "# 002304\n",
    "# Wall time: 28.7 s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.31 s, sys: 429 ms, total: 2.74 s\n",
      "Wall time: 2.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for product in product_list:\n",
    "    if (np.sum(abs(coef_list[product])>1e-8)>-0):\n",
    "        par_get_all_signal(strat, all_dates, product, 4096, SAVE_PATH=SAVE_PATH)\n",
    "\n",
    "## Wall time: 4.56 s\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reverse=1\n",
      "reverse=1\n",
      "reverse=1\n",
      "reverse=1\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for product in product_list:\n",
    "    if (np.sum(abs(coef_list[product])>1e-8)>-0):\n",
    "        evaluate_signal(\"lasso.004\", all_dates, product, 0.001, 20, CORE_NUM, HEAD_PATH, SAVE_PATH,\n",
    "                            period=4096, split_str=\"2017\",atr_filter=0.02, save_path=\"ckpt/signal result atr\", reverse=1)\n",
    "\n",
    "# reverse=1\n",
    "# reverse=1\n",
    "# reverse=1\n",
    "# reverse=1\n",
    "# Wall time: 18min 24s\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for product in product_list:\n",
    "    if (np.sum(abs(coef_list[product])>1e-8)>-0):\n",
    "        signal_stat = load(HEAD_PATH+\"/signal result atr/\"+product+\".\"+\"lasso.004.4096.trend\"+\".pkl\")\n",
    "        train_stat = signal_stat[\"train.stat\"]\n",
    "        good_strat = (train_stat[\"final.result\"][\"avg.ret\"]>0.001)\n",
    "        train_pnl = train_stat[\"daily.pnl\"][:, good_strat].sum(axis=1)/sum(good_strat)\n",
    "        test_stat = signal_stat[\"test.stat\"]\n",
    "        test_pnl = test_stat[\"daily.pnl\"][:, good_strat].sum(axis=1)/sum(good_strat)\n",
    "        print(product, \"train sharpe \", sharpe(train_pnl), \"test sharpe \", sharpe(test_pnl))\n",
    "    \n",
    "# 600519 train sharpe  nan test sharpe  nan\n",
    "# 000858 train sharpe  0.38057701510714226 test sharpe  -0.3008558816921885\n",
    "# 000568 train sharpe  0.2813515578146476 test sharpe  0.03187529849666643\n",
    "# 002304 train sharpe  0.14356210818780926 test sharpe  -0.6376099873371995\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_list = load(SAVE_PATH+\"/wine.coef.ret.4096.002.pkl\")\n",
    "strat = \"lasso.002.\"+str(period)\n",
    "for product in product_list:\n",
    "    os.makedirs(SAVE_PATH+\"/tmp pkl/\"+product+\"/\"+strat, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for product in product_list:\n",
    "    if (np.sum(abs(coef_list[product])>1e-8)>-0):\n",
    "        print(product)\n",
    "        coef = coef_list[product]\n",
    "        parLapply(CORE_NUM, all_dates, par_get_daily_pred, \n",
    "                  product=product, coef=coef, strat=strat, HEAD_PATH=SAVE_PATH)\n",
    "        \n",
    "# 000858\n",
    "# 000568\n",
    "# 600809\n",
    "# 002304\n",
    "# Wall time: 28.2 s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for product in product_list:\n",
    "    if (np.sum(abs(coef_list[product])>1e-8)>-0):\n",
    "        par_get_all_signal(strat, all_dates, product, 4096, SAVE_PATH=SAVE_PATH)\n",
    "\n",
    "#Wall time: 4.33 s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for product in product_list:\n",
    "    if (np.sum(abs(coef_list[product])>1e-8)>-0):\n",
    "        evaluate_signal(\"lasso.002\", all_dates, product, 0.001, 20, CORE_NUM, HEAD_PATH, SAVE_PATH,\n",
    "                            period=4096, split_str=\"2017\",atr_filter=0.02, save_path=\"signal result atr\", reverse=1)\n",
    "        \n",
    "# reverse=1\n",
    "# reverse=1\n",
    "# reverse=1\n",
    "# reverse=1\n",
    "# Wall time: 17min 58s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for product in product_list:\n",
    "    if (np.sum(abs(coef_list[product])>1e-8)>-0):\n",
    "        signal_stat = load(HEAD_PATH+\"/signal result atr/\"+product+\".\"+\"lasso.002.4096.trend\"+\".pkl\")\n",
    "        train_stat = signal_stat[\"train.stat\"]\n",
    "        good_strat = (train_stat[\"final.result\"][\"avg.ret\"]>0.001)\n",
    "        train_pnl = train_stat[\"daily.pnl\"][:, good_strat].sum(axis=1)/sum(good_strat)\n",
    "        test_stat = signal_stat[\"test.stat\"]\n",
    "        test_pnl = test_stat[\"daily.pnl\"][:, good_strat].sum(axis=1)/sum(good_strat)\n",
    "        print(product, \"train sharpe \", sharpe(train_pnl), \"test sharpe \", sharpe(test_pnl))\n",
    "        \n",
    "# 000858 train sharpe  nan test sharpe  nan\n",
    "# 000568 train sharpe  nan test sharpe  nan\n",
    "# 600809 train sharpe  nan test sharpe  nan\n",
    "# 002304 train sharpe  0.3233387998156374 test sharpe  0.42273951806961885\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The result is good\n",
    "- Now we go to ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_signal = 'ret.4096.004'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_list=dict([])\n",
    "\n",
    "for product in product_list:\n",
    "    train_mat = load(HEAD_PATH+\"/train test mat/\"+product+\".train.mat.pkl\")\n",
    "    x_train = train_mat.iloc[:, :n_signal].values\n",
    "    y_train = train_mat.loc[:, y_signal].values\n",
    "    scaler =  StandardScaler(copy=True, with_mean=True, with_std=True)\n",
    "    scaler.fit(x_train)\n",
    "    x_std = np.sqrt(scaler.var_)\n",
    "    y_std = np.std(y_train)\n",
    "    x_train_normal = scaler.transform(x_train)\n",
    "    model = RidgeCV(fit_intercept=False, cv=5).fit(x_train_normal, y_train/y_std)\n",
    "    coef = model.coef_/x_std*y_std\n",
    "    print(product)\n",
    "    print(coef)\n",
    "    coef_list[product] = coef\n",
    "\n",
    "# 600519\n",
    "# [ 1.99528408e-02 -1.14785851e-02 -1.23463858e-03  6.94856700e-04\n",
    "#  -2.11979375e-01  5.21307515e-03 -2.54808272e-03  6.12308523e-03\n",
    "#   2.03401416e-03 -9.10236471e-04 -7.27898886e-04 -3.39503947e-05\n",
    "#  -3.86246526e-04 -8.92302338e-05 -4.45227024e-03 -6.25876719e-03\n",
    "#   1.39950686e-03  2.64326509e-04  3.50808127e-02 -4.51924017e-04\n",
    "#   1.90042259e-03  1.23841161e-01  2.13919361e-03 -2.27525340e-02\n",
    "#   1.10076140e-02 -1.75138258e-02 -1.60660474e-03  3.49551397e-03]\n",
    "# 000858\n",
    "# [-0.020389   -0.00056802  0.02200427 -0.00047172 -0.18048022  0.00256965\n",
    "#   0.00044719  0.08307516  0.01228999  0.00718508 -0.00581727  0.15226992\n",
    "#  -0.0036148   0.00199131  0.16351221 -0.07051018 -0.08974679 -0.00601154\n",
    "#  -0.21612421  0.01274563  0.00711811  0.05667203 -0.01741315 -0.03198155\n",
    "#   0.00935885 -0.31819783  0.00149994 -0.00416277]\n",
    "# 000568\n",
    "# [ 1.07586559e-01  8.90084085e-03  7.73062577e-03  1.76866149e-03\n",
    "#  -2.03793577e-01  2.60423907e-03 -4.06742017e-03  1.76119847e-02\n",
    "#  -6.21031893e-03  7.73856561e-03 -1.54595721e-04 -8.88364973e-03\n",
    "#   1.66412162e-03 -3.23295376e-03 -5.97319788e-03 -3.26512260e-02\n",
    "#   4.05812061e-02 -1.15236581e-02  4.65210070e-02 -3.54357296e-04\n",
    "#  -1.82129070e-02 -2.06465269e-01 -2.14657418e-03 -7.50873545e-04\n",
    "#  -5.11414109e-03  1.97682018e-01  5.05289782e-03  3.91067327e-03]\n",
    "# 600809\n",
    "# [ 0.02979219  0.00819219 -0.00206064 -0.00626476 -0.03363006  0.0041368\n",
    "#   0.00167466 -0.0069235  -0.0077763   0.00593895  0.0002517  -0.00168154\n",
    "#   0.00038114 -0.00136566  0.17225663 -0.00552728 -0.00243395 -0.00517648\n",
    "#   0.00883877  0.00079726 -0.01134891 -0.18792029  0.01368102  0.00284962\n",
    "#   0.01334192 -0.02351089  0.00375842 -0.00122849]\n",
    "# 002304\n",
    "# [-1.32567230e-01  1.43272854e-02  1.19835161e-02  3.17739979e-03\n",
    "#  -1.51619916e-01  2.93112195e-03 -2.42614353e-03  1.65047154e-03\n",
    "#  -8.91141377e-05  3.77997292e-04 -9.04035527e-05  1.02360421e-03\n",
    "#   1.98379292e-04 -1.73399757e-04 -7.01094835e-04 -5.64838436e-03\n",
    "#  -9.74883816e-04 -6.61310331e-04  4.11314653e-04  4.38522508e-05\n",
    "#  -2.77109924e-04  2.00613277e-02  9.06459656e-04 -2.03646653e-03\n",
    "#  -1.16006363e-03  1.11167671e-01  5.88470127e-03 -6.27657873e-03]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save(coef_list, SAVE_PATH+\"/wine.coef.ridge.004.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strat = \"ridge.004.\"+str(period)\n",
    "for product in product_list:\n",
    "    os.makedirs(SAVE_PATH+\"/tmp pkl/\"+product+\"/\"+strat, exist_ok=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for product in product_list:\n",
    "    print(product)\n",
    "    coef = coef_list[product]\n",
    "    parLapply(CORE_NUM, all_dates, par_get_daily_pred, \n",
    "              product=product, coef=coef, strat=strat, HEAD_PATH=SAVE_PATH)\n",
    "\n",
    "# 600276\n",
    "# 000538\n",
    "# 600332\n",
    "# 600436\n",
    "# 600535\n",
    "# Wall time: 25.8 s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for product in product_list:\n",
    "    par_get_all_signal(strat, all_dates, product, 4096, SAVE_PATH=SAVE_PATH)\n",
    "    \n",
    "# Wall time: 2.34 s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for product in product_list:\n",
    "    evaluate_signal(\"ridge.004\", all_dates, product, 0.001, 20, CORE_NUM, HEAD_PATH, SAVE_PATH,\n",
    "                        period=4096, split_str=\"2017\",atr_filter=0.02, save_path=\"signal result atr\", reverse=1)\n",
    "\n",
    "# reverse=1\n",
    "# reverse=1\n",
    "# reverse=1\n",
    "# reverse=1\n",
    "# reverse=1\n",
    "# Wall time: 22min 20s\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for product in product_list:\n",
    "    signal_stat = load(HEAD_PATH+\"/signal result atr/\"+product+\".\"+\"ridge.004.4096.trend\"+\".pkl\")\n",
    "    train_stat = signal_stat[\"train.stat\"]\n",
    "    good_strat = (train_stat[\"final.result\"][\"avg.ret\"]>0.001)\n",
    "    train_pnl = train_stat[\"daily.pnl\"][:, good_strat].sum(axis=1)/sum(good_strat)\n",
    "    test_stat = signal_stat[\"test.stat\"]\n",
    "    test_pnl = test_stat[\"daily.pnl\"][:, good_strat].sum(axis=1)/sum(good_strat)\n",
    "    print(product, \"train sharpe \", sharpe(train_pnl), \"test sharpe \", sharpe(test_pnl))\n",
    "    \n",
    "# 600519 train sharpe  nan test sharpe  nan\n",
    "# 000858 train sharpe  0.34907182116984525 test sharpe  0.24989021542014447\n",
    "# 000568 train sharpe  0.18276877216561643 test sharpe  -0.26042619795187144\n",
    "# 600809 train sharpe  nan test sharpe  nan\n",
    "# 002304 train sharpe  0.6001082863621504 test sharpe  -0.22266388236131687\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNetCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strat = \"elastic.004.\"+str(period)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for product in product_list:\n",
    "    os.makedirs(SAVE_PATH+\"/tmp pkl/\"+product+\"/\"+strat, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "coef_list=dict([])\n",
    "y_signal= \"ret.\" + str(period)+\".004\"\n",
    "for product in product_list:\n",
    "    train_mat = load(HEAD_PATH+\"/train test mat/\"+product+\".train.mat.pkl\")\n",
    "    x_train = train_mat.iloc[:, :n_signal].values\n",
    "    y_train = train_mat.loc[:, y_signal].values\n",
    "    scaler =  StandardScaler(copy=True, with_mean=False, with_std=True)\n",
    "    scaler.fit(x_train)\n",
    "    x_std = np.sqrt(scaler.var_)\n",
    "    y_std = np.std(y_train)\n",
    "    x_train_normal = scaler.transform(x_train)\n",
    "    model = ElasticNetCV(n_alphas=100, l1_ratio=0.5, fit_intercept=False, cv=10, max_iter=10000).fit(x_train_normal, y_train/y_std)\n",
    "    coef = model.coef_/x_std*y_std\n",
    "    print(product)\n",
    "    print(coef)\n",
    "    coef_list[product] = coef\n",
    "\n",
    "# 600519\n",
    "# [ 0.         -0.         -0.         -0.         -0.          0.\n",
    "#  -0.          0.          0.         -0.00068736 -0.         -0.\n",
    "#  -0.         -0.          0.         -0.          0.         -0.\n",
    "#   0.          0.          0.          0.06973003 -0.         -0.\n",
    "#   0.          0.          0.          0.        ]\n",
    "# 000858\n",
    "# [ 0.00000000e+00 -5.45108373e-03  0.00000000e+00 -0.00000000e+00\n",
    "#  -5.83550004e-02  2.02916524e-03  0.00000000e+00  1.72046095e-02\n",
    "#  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00  0.00000000e+00\n",
    "#   0.00000000e+00  0.00000000e+00  0.00000000e+00 -8.11333277e-03\n",
    "#  -0.00000000e+00 -3.80030024e-03 -0.00000000e+00  0.00000000e+00\n",
    "#   0.00000000e+00  0.00000000e+00 -1.86227455e-05 -5.26501924e-03\n",
    "#  -0.00000000e+00 -4.55843632e-02  0.00000000e+00 -0.00000000e+00]\n",
    "# 000568\n",
    "# [-0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0.\n",
    "#  -0. -0. -0. -0. -0. -0. -0. -0. -0. -0.]\n",
    "# 600809\n",
    "# [ 0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
    "#  -0.00000000e+00  0.00000000e+00 -0.00000000e+00  0.00000000e+00\n",
    "#  -5.56393394e-19 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
    "#  -0.00000000e+00 -0.00000000e+00  0.00000000e+00 -0.00000000e+00\n",
    "#  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
    "#  -0.00000000e+00  0.00000000e+00 -0.00000000e+00  0.00000000e+00\n",
    "#   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
    "# 002304\n",
    "# [-0.01113802  0.         -0.         -0.         -0.0244675   0.\n",
    "#  -0.         -0.         -0.         -0.         -0.         -0.\n",
    "#  -0.         -0.         -0.         -0.         -0.         -0.\n",
    "#  -0.         -0.         -0.         -0.          0.         -0.\n",
    "#  -0.         -0.          0.         -0.        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save(coef_list, SAVE_PATH+\"/wine.coef.elastic.004.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strat = \"elastic.004.\"+str(period)\n",
    "for product in product_list:\n",
    "    os.makedirs(SAVE_PATH+\"/tmp pkl/\"+product+\"/\"+strat, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for product in product_list:\n",
    "    print(product)\n",
    "    coef = coef_list[product]\n",
    "    if (np.sum(abs(coef)>1e-8)>0):\n",
    "        parLapply(CORE_NUM, all_dates, par_get_daily_pred, \n",
    "                  product=product, coef=coef, strat=strat, HEAD_PATH=SAVE_PATH)\n",
    "    \n",
    "# 600519\n",
    "# 000858\n",
    "# 000568\n",
    "# 600809\n",
    "# 002304\n",
    "# Wall time: 21.3 s\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for product in product_list:\n",
    "    if (np.sum(abs(coef_list[product])>1e-8)>-0):\n",
    "        par_get_all_signal(strat, all_dates, product, 4096, SAVE_PATH=SAVE_PATH)\n",
    "    \n",
    "# Wall time: 3.42 s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for product in product_list:\n",
    "    if (np.sum(abs(coef_list[product])>1e-8)>-0):\n",
    "        evaluate_signal(\"elastic.004\", all_dates, product, 0.001, 20, CORE_NUM, HEAD_PATH, SAVE_PATH,\n",
    "                            period=4096, split_str=\"2019-08\",atr_filter=0.02, save_path=\"signal result atr\", reverse=1)\n",
    "\n",
    "    \n",
    "# reverse=1\n",
    "# reverse=1\n",
    "# reverse=1\n",
    "# Wall time: 15min 26s\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for product in product_list:\n",
    "    if (np.sum(abs(coef_list[product])>1e-8)>-0):\n",
    "        signal_stat = load(HEAD_PATH+\"/signal result atr/\"+product+\".\"+\"elastic.004.4096.trend\"+\".pkl\")\n",
    "        train_stat = signal_stat[\"train.stat\"]\n",
    "        good_strat = (train_stat[\"final.result\"][\"avg.ret\"]>0.001)\n",
    "        train_pnl = train_stat[\"daily.pnl\"][:, good_strat].sum(axis=1)/sum(good_strat)\n",
    "        test_stat = signal_stat[\"test.stat\"]\n",
    "        test_pnl = test_stat[\"daily.pnl\"][:, good_strat].sum(axis=1)/sum(good_strat)\n",
    "        print(product, \"train sharpe \", sharpe(train_pnl), \"test sharpe \", sharpe(test_pnl))\n",
    "\n",
    "# 600519 train sharpe  0.35428100359249076 test sharpe  1.0920916649060126\n",
    "# 000858 train sharpe  0.6502682398133942 test sharpe  -0.7318608191345223\n",
    "# 002304 train sharpe  0.19434894619569948 test sharpe  -1.3986880659860967"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- output to txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"d:/intern/input\", exist_ok=True)\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for product in product_list:\n",
    "    file_name = \"d:/intern/input/\"+product+\".signal.txt\"\n",
    "    fo = open(file_name, \"w\")\n",
    "    fo.writelines(\"signal coef\\n\")\n",
    "    chosen_signal = coef_list[product]!=0\n",
    "    for i in np.where(chosen_signal)[0]:\n",
    "        fo.writelines(signal_list[i]+\" \"+str(coef_list[product][i])+\"\\n\")\n",
    "    fo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "30px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": true,
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
