{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEAD_PATH = './'\n",
    "DATA_PATH = HEAD_PATH + \"data/stocks/\"\n",
    "SAVE_PATH = HEAD_PATH + \"ckpt/\"\n",
    "TEMP_PATH = SAVE_PATH + \"tmp pkl/\"\n",
    "OUTPUT_PATH = HEAD_PATH + 'output'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Welcome to Quantitative and High Frequency Trading Training Program\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'stock_stats' from '/Users/junsu/Dropbox/workspace/stock_official/stock_stats.py'>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from stock_helper import *\n",
    "from stock_stats import *\n",
    "from imp import reload  \n",
    "import stock_helper\n",
    "import stock_stats\n",
    "reload(stock_helper)\n",
    "reload(stock_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overwrite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "def get_hft_summary(result, thre_mat):\n",
    "    n_thre = np.shape(thre_mat)[0]\n",
    "    all_pnl = np.zeros((0,n_thre))\n",
    "    all_dates = np.array([])\n",
    "    for i in range(len(result)):\n",
    "        all_pnl =  np.concatenate((all_pnl,result[i][\"all.pnl\"]),axis=0)\n",
    "        all_dates = np.append(all_dates, result[i][\"date\"])\n",
    "    stat = result[0][\"result\"].iloc[:,2:]\n",
    "    for i in range(1,len(result)):\n",
    "        stat = stat+result[i][\"result\"].iloc[:,2:]\n",
    "    stat[\"avg.ret\"]=stat[\"ret\"]/stat[\"num\"]\n",
    "    \n",
    "    total_ret = all_pnl.sum(0)\n",
    "    total_sharpe = np.zeros(n_thre)\n",
    "    total_drawdown = np.zeros(n_thre)\n",
    "    total_max_drawdown = np.zeros(n_thre)\n",
    "    for i in range(n_thre):\n",
    "        total_sharpe[i] = sharpe(all_pnl[:,i])\n",
    "        total_drawdown[i] = drawdown(all_pnl[:,i])\n",
    "        total_max_drawdown[i] = max_drawdown(all_pnl[:,i])\n",
    "    final_result = pd.DataFrame(data=OrderedDict([(\"open\", thre_mat[\"open\"]), (\"close\", thre_mat[\"close\"]), (\"num\", stat[\"num\"]),\n",
    "                                                  (\"avg.ret\", stat[\"avg.ret\"]), (\"total.ret\",total_ret), (\"sharpe\", total_sharpe),\n",
    "                                                  (\"drawdown\", total_drawdown), (\"max.drawdown\", total_max_drawdown),\n",
    "                                                 (\"mar\", total_ret/total_max_drawdown)]), \n",
    "                                index=thre_mat.index)\n",
    "    return OrderedDict([(\"final.result\", final_result), (\"daily.pnl\", all_pnl), (\"date\", all_dates)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_signal(file_list, product, signal_name, period, HEAD_PATH=\"d:/intern\", SIGNAL_PATH=\"d:/intern\"):\n",
    "    n_files = len(file_list)\n",
    "    all_signal = np.array([])\n",
    "    for file in file_list:\n",
    "        S = load(SIGNAL_PATH+\"/tmp pkl/\"+product+\"/\"+signal_name+\"/\"+file)\n",
    "        signal = S\n",
    "        #moving_average(signal,period)\n",
    "        chosen = (np.arange(len(signal))+1) % period==0\n",
    "        all_signal = np.concatenate((all_signal, signal[chosen]), axis=0)\n",
    "    return all_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get backtest result of a signal on a product's list\n",
    "from collections import OrderedDict\n",
    "def get_list_signal_stat(signal_name, thre_mat_list, product_list, atr_filter_list,\n",
    "                    split_str=\"2018\", min_pnl=2, min_num=20, reverse=1):\n",
    "    CORE_NUM = 11#int(os.environ['NUMBER_OF_PROCESSORS'])\n",
    "    train_trade_stat = dict([]) ## training result statistics\n",
    "    print(\"training\")\n",
    "    for product in product_list:\n",
    "        print(product)\n",
    "        all_dates = np.array(list(map(lambda x: x, sorted(os.listdir(DATA_PATH + product)))))\n",
    "        train_sample = np.array(all_dates)<split_str ## training samples\n",
    "        test_sample = np.array(all_dates)>split_str ## test samples\n",
    "        print(sum(train_sample), sum(test_sample))\n",
    "        thre_mat = thre_mat_list[product]\n",
    "        atr_filter = atr_filter_list[product]\n",
    "        with dask.config.set(scheduler='processes', num_workers=CORE_NUM):\n",
    "            f_par = functools.partial(get_signal_pnl, product=product, signal_name=signal_name, thre_mat=thre_mat,\n",
    "                                 reverse=1,\n",
    "                                HEAD_PATH=HEAD_PATH, SAVE_PATH=SAVE_PATH,atr_filter=atr_filter)\n",
    "            train_result = compute([delayed(f_par)(file) for file in np.array(all_dates)[train_sample]])[0]\n",
    "        trade_stat = get_hft_summary(train_result, thre_mat)\n",
    "        train_trade_stat[product] = trade_stat\n",
    "    print(\"testing\")\n",
    "    test_trade_stat = dict([])\n",
    "    for product in product_list:\n",
    "        all_dates = np.array(list(map(lambda x: x,os.listdir(DATA_PATH + product))))\n",
    "        print(product)\n",
    "        train_sample = np.array(all_dates)<split_str ## training samples\n",
    "        test_sample = np.array(all_dates)>split_str ## test samples\n",
    "        thre_mat = thre_mat_list[product]\n",
    "        reverse = reverse_list[product]\n",
    "        atr_filter = atr_filter_list[product]\n",
    "        with dask.config.set(scheduler='processes', num_workers=CORE_NUM):\n",
    "            f_par = functools.partial(get_signal_pnl, product=product, signal_name=signal_name, thre_mat=thre_mat,\n",
    "                                 reverse=1,\n",
    "                                HEAD_PATH=HEAD_PATH, SAVE_PATH=SAVE_PATH,atr_filter=atr_filter)\n",
    "            result = compute([delayed(f_par)(file) for file in np.array(all_dates)[test_sample]])[0]\n",
    "        trade_stat = get_hft_summary(result, thre_mat)\n",
    "        test_trade_stat[product] = trade_stat\n",
    "    result=dict([])\n",
    "    result[\"train_trade_stat\"] = train_trade_stat ## save train stat\n",
    "    result[\"test_trade_stat\"] = test_trade_stat ## save test stat\n",
    "    if reverse==-1:\n",
    "        save(result, OUTPUT_PATH+\"/\"+signal_name+\".result.pkl\") ## reversal strategy\n",
    "    else:\n",
    "        save(result, OUTPUT_PATH+\"/\"+signal_name+\".pos.result.pkl\") ## trend strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "def get_signal_pnl(file, product, signal_name, thre_mat, reverse=1,  buy_tranct=1.5e-4, sell_tranct=11.5e-4,\n",
    "                   max_spread=0.011,\n",
    "                   HEAD_PATH=HEAD_PATH, SAVE_PATH=SAVE_PATH, atr_filter=0):\n",
    "    ## load data\n",
    "    data = load(DATA_PATH+product+\"/\"+file)\n",
    "    S = load(SAVE_PATH+\"/tmp pkl/\"+product+\"/\"+signal_name+\"/\"+file)\n",
    "    pred = S*reverse\n",
    "    atr = load(SAVE_PATH+\"/tmp pkl/\"+product+\"/\"+\"atr.4096\"+\"/\"+file)\n",
    "    #n_bar = len(data)\n",
    "    \n",
    "    ## load signal\n",
    "    \n",
    "    ## we don't know the signal is positive correlated or negative correlated  \n",
    "    #n_thre = len(thre_mat)\n",
    "    date = np.array([x[0:10] for x in data[\"date.time\"]])\n",
    "    next_date = np.append(date[1:],'1')\n",
    "    end_day = date!=next_date\n",
    "    count = 0;\n",
    "    n_day = sum(end_day)\n",
    "    n_thre = np.shape(thre_mat)[0]\n",
    "    all_pnl = np.zeros((n_day, n_thre))\n",
    "    result = pd.DataFrame(data=OrderedDict([(\"open\", thre_mat[\"open\"].values), (\"close\", thre_mat[\"close\"].values),\n",
    "                               (\"num\", 0), (\"avg.ret\", 0), (\"ret\", 0)]), \n",
    "                          index=thre_mat.index)\n",
    "\n",
    "    cur_spread = data[\"ask1\"]-data[\"bid1\"]\n",
    "    for thre in thre_mat.iterrows():\n",
    "        count = count+1\n",
    "        buy = pred>thre[1][\"open\"]\n",
    "        sell = pred<-thre[1][\"open\"]\n",
    "        signal = pd.Series(data=0, index=data.index)\n",
    "        position = signal.copy()\n",
    "        signal[buy] = 1\n",
    "        signal[sell] = -1\n",
    "        signal[atr<atr_filter]=0\n",
    "        scratch = -thre[1][\"close\"]\n",
    "        position_pos = pd.Series(data=np.nan, index=data.index)\n",
    "        position_pos.iloc[0] = 0\n",
    "        position_pos[(signal==1) & (data[\"next.ask\"]>0) & (data[\"next.bid\"]>0) & (cur_spread<max_spread)] = 1\n",
    "        position_pos[(pred< -scratch) & (data[\"next.bid\"]>0) & (cur_spread<max_spread)] = 0\n",
    "        position_pos.ffill(inplace=True)\n",
    "        pre_pos = position_pos.shift(1)\n",
    "        notional_position_pos = pd.Series(data=0, index=data.index)\n",
    "        notional_position_pos[position_pos==1] = 1\n",
    "        notional_position_pos[(position_pos==1) & (pre_pos==1)] = np.nan\n",
    "        notional_position_pos[(notional_position_pos==1)] = 1/data[\"next.ask\"][(notional_position_pos==1)]\n",
    "        notional_position_pos.ffill(inplace=True)\n",
    "        position_neg = pd.Series(data=np.nan, index=data.index)\n",
    "        position_neg.iloc[0] = 0\n",
    "        position_neg[(signal==-1) & (data[\"next.ask\"]>0) & (data[\"next.bid\"]>0) & (cur_spread<max_spread)] = -1\n",
    "        position_neg[(pred> scratch) & (data[\"next.ask\"]>0) & (cur_spread<max_spread)] = 0\n",
    "        position_neg.ffill(inplace=True)\n",
    "        pre_neg = position_neg.shift(1)\n",
    "        notional_position_neg = pd.Series(data=0, index=data.index)\n",
    "        notional_position_neg[position_neg==-1] = -1\n",
    "        notional_position_neg[(position_neg==-1) & (pre_neg==-1)] = np.nan\n",
    "        notional_position_neg[(notional_position_neg==-1)] = -1/data[\"next.bid\"][(notional_position_neg==-1)]\n",
    "        notional_position_neg.ffill(inplace=True)\n",
    "        position = position_pos + position_neg\n",
    "        notional_position = notional_position_pos+notional_position_neg\n",
    "        #position[n_bar-1] = 0\n",
    "        position.iloc[0] = 0\n",
    "        position.iloc[-2:] = 0\n",
    "        notional_position.iloc[0] = 0\n",
    "        notional_position.iloc[-2:] = 0\n",
    "        #change_pos = position - position.shift(1)\n",
    "        #notional_change_pos = notional_position-notional_position.shift(1)\n",
    "        change_pos = notional_position-notional_position.shift(1)\n",
    "        change_pos.iloc[0] = 0\n",
    "        #notional_change_pos.iloc[0] = 0\n",
    "        change_base = pd.Series(data=0, index=data.index)\n",
    "        change_buy = change_pos>0\n",
    "        change_sell = change_pos<0\n",
    "        change_base[change_buy] = data[\"next.ask\"][change_buy]*(1+buy_tranct)*data[\"adjust\"]\n",
    "        change_base[change_sell] = data[\"next.bid\"][change_sell]*(1-sell_tranct)*data[\"adjust\"]\n",
    "        raw_pnl = -(change_base*change_pos).cumsum()+notional_position*data[\"wpr\"]\n",
    "        final_pnl = -sum(change_base*change_pos) ## total pnl, there is a negative sign, because selling get money and buying pay money\n",
    "        turnover = sum(change_base*abs(change_pos))\n",
    "        num = sum((position!=0) & (change_pos!=0)) ## number of trades\n",
    "        hld_period = sum(position!=0)   ## holding period\n",
    "        daily_pnl = raw_pnl[end_day].reset_index(drop=True)\n",
    "        pnl = np.append(daily_pnl[0], np.diff(daily_pnl))\n",
    "        all_pnl[:,thre[0]] = pnl\n",
    "        if (num==0):\n",
    "            result.loc[thre[0], (\"num\",\"avg.ret\",\"ret\")] = (0,0,0)\n",
    "        else:\n",
    "            result.loc[thre[0],(\"num\", \"avg.ret\", \"ret\", )] = (num, final_pnl/num, final_pnl)\n",
    "    return OrderedDict([(\"all.pnl\", all_pnl), (\"result\", result), (\"date\", date[end_day])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function stock_helper.get_signal_pnl(file, product, signal_name, thre_mat, reverse=1, tranct=0.00011, max_spread=0.61, tranct_ratio=True, HEAD_PATH='d:/intern', SAVE_PATH='d:/intern', atr_filter=0, rebate=0)>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_signal_pnl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    " \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- number of cores, set this number according to your computer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CORE_NUM = int(os.environ['NUMBER_OF_PROCESSORS'])\n",
    "CORE_NUM =11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- sample product, you can change to your specific product symbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_list = [\"600519\", \"000858\", \"000568\", \"600809\", \"002304\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "from dask import compute, delayed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- sample period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "period = 4096\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_dates = os.listdir(DATA_PATH + product_list[0])\n",
    "all_dates.sort()\n",
    "all_dates = np.array(all_dates)\n",
    "n_days = len(all_dates)\n",
    "n_days\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- choose an example day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sample = all_dates<\"2017\"\n",
    "\n",
    "test_sample = all_dates>\"2017\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- at last we plot the selected pnl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- now we can see that the number of signals are not very big\n",
    "- and the quality is not so good\n",
    "- we can propose a systematic method to generate a large number of signals then\n",
    "- we can choose good ones from them\n",
    "\n",
    "- for example, we can first generate some signals about volatility without direction\n",
    "- there are some ideas about it\n",
    "\n",
    "- standard deviation\n",
    "- range of price\n",
    "- ratio of volume to turnover\n",
    "\n",
    "- then we can generate some signals with direction\n",
    "- actually all of our previous signals have direction\n",
    "- but some of them are good and some of them are bad\n",
    "- we can focus on some good and simple ones, such as\n",
    "\n",
    "- normalized return\n",
    "- rsi\n",
    "- dbook\n",
    "\n",
    "- let's try to generate range signals first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "## calculate rolling standard deviation\n",
    "from collections import OrderedDict\n",
    "class foctor_std_period(factor_template):\n",
    "    factor_name = \"std.period\"\n",
    "    \n",
    "    params = OrderedDict([\n",
    "        (\"period\", np.power(2, range(12,13)))\n",
    "    ])\n",
    "    \n",
    "    def formula(self, data, period):\n",
    "        return np.sqrt(fast_roll_var(data[\"wpr\"], period))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "## calcualte rolling variance\n",
    "def fast_roll_var(x, period):\n",
    "    x_ma = cum(x,period)/period ## roling first moment\n",
    "    x2 = x*x\n",
    "    x2_ma = cum(x2,period)/period ## rolling second moment\n",
    "    var_x = x2_ma-x_ma*x_ma ## rolling variance\n",
    "    return(var_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./ckpt//tmp pkl/600519/std.4096\n",
      "./ckpt//tmp pkl/000858/std.4096\n",
      "./ckpt//tmp pkl/000568/std.4096\n",
      "./ckpt//tmp pkl/600809/std.4096\n",
      "./ckpt//tmp pkl/002304/std.4096\n"
     ]
    }
   ],
   "source": [
    "x20 = foctor_std_period()\n",
    "for product in product_list:\n",
    "    create_signal_path(x20, product, SAVE_PATH);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 236 ms, sys: 283 ms, total: 520 ms\n",
      "Wall time: 34.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for product in product_list:\n",
    "    file_list = list(map(lambda x: DATA_PATH+product+\"/\"+x, sorted(os.listdir(DATA_PATH + product))))\n",
    "    parLapply(CORE_NUM, file_list, build_composite_signal,signal_list=x20, product=product, HEAD_PATH=SAVE_PATH, n=8)\n",
    "    \n",
    "# Wall time: 1min 47s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "## rolling price range\n",
    "from collections import OrderedDict\n",
    "class foctor_range_period(factor_template):\n",
    "    factor_name = \"range.period\"\n",
    "    \n",
    "    params = OrderedDict([\n",
    "        (\"period\", np.power(2, range(12,13)))\n",
    "    ])\n",
    "    \n",
    "    def formula(self, data, period):\n",
    "        return data[\"max.\"+str(period)]-data[\"min.\"+str(period)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./ckpt//tmp pkl/600519/range.4096\n",
      "./ckpt//tmp pkl/000858/range.4096\n",
      "./ckpt//tmp pkl/000568/range.4096\n",
      "./ckpt//tmp pkl/600809/range.4096\n",
      "./ckpt//tmp pkl/002304/range.4096\n"
     ]
    }
   ],
   "source": [
    "x21 = foctor_range_period()\n",
    "for product in product_list:\n",
    "    create_signal_path(x21, product, SAVE_PATH);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 169 ms, sys: 252 ms, total: 420 ms\n",
      "Wall time: 28.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for product in product_list:\n",
    "    file_list = list(map(lambda x: DATA_PATH+product+\"/\"+x, sorted(os.listdir(DATA_PATH + product))))\n",
    "    parLapply(CORE_NUM, file_list, build_composite_signal,signal_list=x21, product=product, HEAD_PATH=SAVE_PATH, n=8)\n",
    "    \n",
    "## Wall time: 1min 8s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "## rolling trend index\n",
    "from collections import OrderedDict\n",
    "class foctor_trend_index_period(factor_template):\n",
    "    factor_name = \"trend.index.period\"\n",
    "    \n",
    "    params = OrderedDict([\n",
    "        (\"period\", np.power(2, range(12,13)))\n",
    "    ])\n",
    "    \n",
    "    def formula(self, data, period):\n",
    "        aa = zero_divide(abs(data[\"wpr\"]-data[\"wpr\"].shift(period)), data[\"max.\"+str(period)]-data[\"min.\"+str(period)])\n",
    "        aa[0:period]=0\n",
    "        return aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./ckpt//tmp pkl/600519/trend.index.4096\n",
      "./ckpt//tmp pkl/000858/trend.index.4096\n",
      "./ckpt//tmp pkl/000568/trend.index.4096\n",
      "./ckpt//tmp pkl/600809/trend.index.4096\n",
      "./ckpt//tmp pkl/002304/trend.index.4096\n"
     ]
    }
   ],
   "source": [
    "x23 = foctor_trend_index_period()\n",
    "for product in product_list:\n",
    "    create_signal_path(x23, product, SAVE_PATH);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Then we construt these range signals "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 236 ms, sys: 262 ms, total: 498 ms\n",
      "Wall time: 29.1 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "for product in product_list:\n",
    "    file_list = list(map(lambda x: DATA_PATH+product+\"/\"+x, sorted(os.listdir(DATA_PATH + product))))\n",
    "    parLapply(CORE_NUM, file_list, build_composite_signal,signal_list=x20, product=product, HEAD_PATH=SAVE_PATH, n=8)\n",
    ";\n",
    "# Wall time: 1min 11s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 226 ms, sys: 263 ms, total: 489 ms\n",
      "Wall time: 29.2 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "for product in product_list:\n",
    "    file_list = list(map(lambda x: DATA_PATH+product+\"/\"+x, sorted(os.listdir(DATA_PATH + product))))\n",
    "    parLapply(CORE_NUM, file_list, build_composite_signal,signal_list=x23, product=product, HEAD_PATH=SAVE_PATH,n=8)\n",
    ";\n",
    "\n",
    "## Wall time: 1min 14s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now we can combine directional signals and range signals together to become new direction signals\n",
    "\n",
    "- For example, we have n directional signals, and m range signals, \n",
    "- then we can generate new n*m directional signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "## generate composite signal: trend signal * range signal = new trend signal\n",
    "def construct_composite_signal(dire_signal, range_signal, period_list, product_list, HEAD_PATH):\n",
    "    from collections import OrderedDict\n",
    "    class foctor_xx_period(factor_template):\n",
    "        factor_name = dire_signal+\".\"+range_signal+\".period\" ## name of new signal\n",
    "        params = OrderedDict([\n",
    "            (\"period\", period_list)\n",
    "        ])\n",
    "        def formula(self, data, period):\n",
    "            return (data[dire_signal+\".\"+str(period)]*data[range_signal+\".\"+str(period)]).values ## calculation of new signal\n",
    "    xx = foctor_xx_period()\n",
    "    for product in product_list:\n",
    "        create_signal_path(xx, product, HEAD_PATH)\n",
    "        file_list = list(map(lambda x: DATA_PATH+product+\"/\"+x, sorted(os.listdir(DATA_PATH + product))))\n",
    "        parLapply(CORE_NUM, file_list, build_composite_signal,signal_list=xx, product=product, HEAD_PATH=HEAD_PATH,n=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "## generate composite signal: trend signal * range signal = new trend signal\n",
    "def construct_composite_signal(dire_signal, range_signal, period_list, product_list, HEAD_PATH):\n",
    "    from collections import OrderedDict\n",
    "    class foctor_xx_period(factor_template):\n",
    "        factor_name = dire_signal+\".\"+range_signal+\".period\" ## name of new signal\n",
    "        params = OrderedDict([\n",
    "            (\"period\", period_list)\n",
    "        ])\n",
    "        def formula(self, data, period):\n",
    "            return (data[dire_signal+\".\"+str(period)]*data[range_signal+\".\"+str(period)]).values ## calculation of new signal\n",
    "    xx = foctor_xx_period()\n",
    "    for product in product_list:\n",
    "        create_signal_path(xx, product, HEAD_PATH)\n",
    "        file_list = list(map(lambda x: DATA_PATH+product+\"/\"+x, sorted(os.listdir(DATA_PATH + product))))\n",
    "        parLapply(CORE_NUM, file_list, build_composite_signal,signal_list=xx, product=product, HEAD_PATH=HEAD_PATH,n=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "dire_signal_list = [\"nr\", \"dbook\", \"range.pos\", \"price.osci\", \"ma.dif.10\", \"kdj.k\", \"kdj.j\"]\n",
    "range_signal_list = [\"range\", \"std\", \"trend.index\"]\n",
    "period_list = np.power(2, range(12,13))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./ckpt//tmp pkl/600519/nr.range.4096\n",
      "./ckpt//tmp pkl/000858/nr.range.4096\n",
      "./ckpt//tmp pkl/000568/nr.range.4096\n",
      "./ckpt//tmp pkl/600809/nr.range.4096\n",
      "./ckpt//tmp pkl/002304/nr.range.4096\n",
      "./ckpt//tmp pkl/600519/dbook.range.4096\n",
      "./ckpt//tmp pkl/000858/dbook.range.4096\n",
      "./ckpt//tmp pkl/000568/dbook.range.4096\n",
      "./ckpt//tmp pkl/600809/dbook.range.4096\n",
      "./ckpt//tmp pkl/002304/dbook.range.4096\n",
      "./ckpt//tmp pkl/600519/range.pos.range.4096\n",
      "./ckpt//tmp pkl/000858/range.pos.range.4096\n",
      "./ckpt//tmp pkl/000568/range.pos.range.4096\n",
      "./ckpt//tmp pkl/600809/range.pos.range.4096\n",
      "./ckpt//tmp pkl/002304/range.pos.range.4096\n",
      "./ckpt//tmp pkl/600519/price.osci.range.4096\n",
      "./ckpt//tmp pkl/000858/price.osci.range.4096\n",
      "./ckpt//tmp pkl/000568/price.osci.range.4096\n",
      "./ckpt//tmp pkl/600809/price.osci.range.4096\n",
      "./ckpt//tmp pkl/002304/price.osci.range.4096\n",
      "./ckpt//tmp pkl/600519/ma.dif.10.range.4096\n",
      "./ckpt//tmp pkl/000858/ma.dif.10.range.4096\n",
      "./ckpt//tmp pkl/000568/ma.dif.10.range.4096\n",
      "./ckpt//tmp pkl/600809/ma.dif.10.range.4096\n",
      "./ckpt//tmp pkl/002304/ma.dif.10.range.4096\n",
      "./ckpt//tmp pkl/600519/kdj.k.range.4096\n",
      "./ckpt//tmp pkl/000858/kdj.k.range.4096\n",
      "./ckpt//tmp pkl/000568/kdj.k.range.4096\n",
      "./ckpt//tmp pkl/600809/kdj.k.range.4096\n",
      "./ckpt//tmp pkl/002304/kdj.k.range.4096\n",
      "./ckpt//tmp pkl/600519/kdj.j.range.4096\n",
      "./ckpt//tmp pkl/000858/kdj.j.range.4096\n",
      "./ckpt//tmp pkl/000568/kdj.j.range.4096\n",
      "./ckpt//tmp pkl/600809/kdj.j.range.4096\n",
      "./ckpt//tmp pkl/002304/kdj.j.range.4096\n",
      "./ckpt//tmp pkl/600519/nr.std.4096\n",
      "./ckpt//tmp pkl/000858/nr.std.4096\n",
      "./ckpt//tmp pkl/000568/nr.std.4096\n",
      "./ckpt//tmp pkl/600809/nr.std.4096\n",
      "./ckpt//tmp pkl/002304/nr.std.4096\n",
      "./ckpt//tmp pkl/600519/dbook.std.4096\n",
      "./ckpt//tmp pkl/000858/dbook.std.4096\n",
      "./ckpt//tmp pkl/000568/dbook.std.4096\n",
      "./ckpt//tmp pkl/600809/dbook.std.4096\n",
      "./ckpt//tmp pkl/002304/dbook.std.4096\n",
      "./ckpt//tmp pkl/600519/range.pos.std.4096\n",
      "./ckpt//tmp pkl/000858/range.pos.std.4096\n",
      "./ckpt//tmp pkl/000568/range.pos.std.4096\n",
      "./ckpt//tmp pkl/600809/range.pos.std.4096\n",
      "./ckpt//tmp pkl/002304/range.pos.std.4096\n",
      "./ckpt//tmp pkl/600519/price.osci.std.4096\n",
      "./ckpt//tmp pkl/000858/price.osci.std.4096\n",
      "./ckpt//tmp pkl/000568/price.osci.std.4096\n",
      "./ckpt//tmp pkl/600809/price.osci.std.4096\n",
      "./ckpt//tmp pkl/002304/price.osci.std.4096\n",
      "./ckpt//tmp pkl/600519/ma.dif.10.std.4096\n",
      "./ckpt//tmp pkl/000858/ma.dif.10.std.4096\n",
      "./ckpt//tmp pkl/000568/ma.dif.10.std.4096\n",
      "./ckpt//tmp pkl/600809/ma.dif.10.std.4096\n",
      "./ckpt//tmp pkl/002304/ma.dif.10.std.4096\n",
      "./ckpt//tmp pkl/600519/kdj.k.std.4096\n",
      "./ckpt//tmp pkl/000858/kdj.k.std.4096\n",
      "./ckpt//tmp pkl/000568/kdj.k.std.4096\n",
      "./ckpt//tmp pkl/600809/kdj.k.std.4096\n",
      "./ckpt//tmp pkl/002304/kdj.k.std.4096\n",
      "./ckpt//tmp pkl/600519/kdj.j.std.4096\n",
      "./ckpt//tmp pkl/000858/kdj.j.std.4096\n",
      "./ckpt//tmp pkl/000568/kdj.j.std.4096\n",
      "./ckpt//tmp pkl/600809/kdj.j.std.4096\n",
      "./ckpt//tmp pkl/002304/kdj.j.std.4096\n",
      "./ckpt//tmp pkl/600519/nr.trend.index.4096\n",
      "./ckpt//tmp pkl/000858/nr.trend.index.4096\n",
      "./ckpt//tmp pkl/000568/nr.trend.index.4096\n",
      "./ckpt//tmp pkl/600809/nr.trend.index.4096\n",
      "./ckpt//tmp pkl/002304/nr.trend.index.4096\n",
      "./ckpt//tmp pkl/600519/dbook.trend.index.4096\n",
      "./ckpt//tmp pkl/000858/dbook.trend.index.4096\n",
      "./ckpt//tmp pkl/000568/dbook.trend.index.4096\n",
      "./ckpt//tmp pkl/600809/dbook.trend.index.4096\n",
      "./ckpt//tmp pkl/002304/dbook.trend.index.4096\n",
      "./ckpt//tmp pkl/600519/range.pos.trend.index.4096\n",
      "./ckpt//tmp pkl/000858/range.pos.trend.index.4096\n",
      "./ckpt//tmp pkl/000568/range.pos.trend.index.4096\n",
      "./ckpt//tmp pkl/600809/range.pos.trend.index.4096\n",
      "./ckpt//tmp pkl/002304/range.pos.trend.index.4096\n",
      "./ckpt//tmp pkl/600519/price.osci.trend.index.4096\n",
      "./ckpt//tmp pkl/000858/price.osci.trend.index.4096\n",
      "./ckpt//tmp pkl/000568/price.osci.trend.index.4096\n",
      "./ckpt//tmp pkl/600809/price.osci.trend.index.4096\n",
      "./ckpt//tmp pkl/002304/price.osci.trend.index.4096\n",
      "./ckpt//tmp pkl/600519/ma.dif.10.trend.index.4096\n",
      "./ckpt//tmp pkl/000858/ma.dif.10.trend.index.4096\n",
      "./ckpt//tmp pkl/000568/ma.dif.10.trend.index.4096\n",
      "./ckpt//tmp pkl/600809/ma.dif.10.trend.index.4096\n",
      "./ckpt//tmp pkl/002304/ma.dif.10.trend.index.4096\n",
      "./ckpt//tmp pkl/600519/kdj.k.trend.index.4096\n",
      "./ckpt//tmp pkl/000858/kdj.k.trend.index.4096\n",
      "./ckpt//tmp pkl/000568/kdj.k.trend.index.4096\n",
      "./ckpt//tmp pkl/600809/kdj.k.trend.index.4096\n",
      "./ckpt//tmp pkl/002304/kdj.k.trend.index.4096\n",
      "./ckpt//tmp pkl/600519/kdj.j.trend.index.4096\n",
      "./ckpt//tmp pkl/000858/kdj.j.trend.index.4096\n",
      "./ckpt//tmp pkl/000568/kdj.j.trend.index.4096\n",
      "./ckpt//tmp pkl/600809/kdj.j.trend.index.4096\n",
      "./ckpt//tmp pkl/002304/kdj.j.trend.index.4096\n",
      "CPU times: user 3.66 s, sys: 5.13 s, total: 8.79 s\n",
      "Wall time: 11min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for range_signal in range_signal_list:\n",
    "    for dire_signal in dire_signal_list:\n",
    "        construct_composite_signal(dire_signal, range_signal, period_list, product_list, SAVE_PATH)\n",
    "##ã€€Wall time: 25min 19s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now we can combine signals of each day in to a vector\n",
    "- here we use 4096 as period\n",
    "- so to keep them independent, we choose 1 out of every 4096 points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "period = 4096\n",
    "os.makedirs(HEAD_PATH+\"/all signal\", exist_ok=True)\n",
    "dire_signal_list = [\"nr\", \"dbook\", \"range.pos\", \"price.osci\", \"ma.dif.10\", \"kdj.k\", \"kdj.j\"]\n",
    "range_signal_list = [\"\", \"range\", \"std\", \"trend.index\"]\n",
    "all_signal_list = np.array([])\n",
    "for range_signal in range_signal_list:\n",
    "    for dire_signal in dire_signal_list:\n",
    "        if len(range_signal)==0:\n",
    "            signal_name = dire_signal\n",
    "        else:\n",
    "            signal_name = dire_signal+\".\"+range_signal\n",
    "        all_signal_list = np.append(all_signal_list,signal_name)\n",
    "all_period_signal = [signal+\".4096\" for signal in all_signal_list]\n",
    "len(all_period_signal)\n",
    "## 28"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- we have 9 directional (trend) signals and 4 range signals\n",
    "- so we have 36 composite signals \n",
    "- plus the 9 original ones we have 45 signals together\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_average(a, n=3) :\n",
    "    ret_sum = np.cumsum(a, dtype=float)\n",
    "    ret = a\n",
    "    ret[n:] = (ret_sum[n:] - ret_sum[:-n])/n\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "## parallel generate the distribution of a signal\n",
    "def par_get_all_signal(signal_name, file_list, product, period, HEAD_PATH=\"d:/intern\", SAVE_PATH=\"e:/intern\", DATA_PATH=\"d:/intern\"):\n",
    "    n_files = len(file_list)\n",
    "    all_signal = np.array([])\n",
    "    for file in file_list:\n",
    "        signal = load(HEAD_PATH+\"/tmp pkl/\"+product+\"/\"+signal_name+\"/\"+file) ## signal\n",
    "        #moving_average(signal,period)\n",
    "        chosen = (np.arange(len(signal))+1) % period==0\n",
    "        all_signal = np.concatenate((all_signal, signal[chosen]), axis=0)\n",
    "    save(all_signal, SAVE_PATH+\"/all signal/\"+product+\".\"+signal_name+\".pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 340 ms, sys: 273 ms, total: 613 ms\n",
      "Wall time: 16.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for product in product_list:\n",
    "    all_dates = sorted(os.listdir(DATA_PATH + product))\n",
    "    parLapply(CORE_NUM, all_period_signal, par_get_all_signal, file_list=all_dates, product=product, period=4096, HEAD_PATH=SAVE_PATH,\n",
    "             SAVE_PATH = SAVE_PATH, DATA_PATH=DATA_PATH);\n",
    "## Wall time: 28.5 s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- then we can backtest our signals \n",
    "- we save the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "## this is to evalute the performance of a signal on a product\n",
    "def evaluate_signal(signal, all_dates, product, min_pnl, min_num, \n",
    "                    CORE_NUM, HEAD_PATH=\"d:/intern\", SIGNAL_PATH=\"d:/intern\", period=4096, split_str=\"2018\", \n",
    "                    atr_filter=0, save_path=\"signal result\",reverse=0):\n",
    "    signal_name = signal+\".\"+str(period) ## signal name, with period\n",
    "    all_signal = load(SIGNAL_PATH+\"/all signal/\"+product+\".\"+signal_name+\".pkl\") ## get the distribution of the signal\n",
    "    open_list = np.quantile(abs(all_signal), np.append(np.arange(0.991,0.999,0.001),np.arange(0.9991,0.9999,0.0001))) ## open threshold\n",
    "    thre_list = []\n",
    "    for cartesian in itertools.product(open_list, np.array([0.2, 0.4, 0.6, 0.8, 1.0])): ## close threshold\n",
    "        thre_list.append((cartesian[0], -cartesian[0] * cartesian[1]))\n",
    "    thre_list = np.array(thre_list)\n",
    "    thre_mat = pd.DataFrame(data=OrderedDict([(\"open\", thre_list[:, 0]), (\"close\", thre_list[:, 1])])) ## threshold matrix\n",
    "    \n",
    "    if reverse>=0: ## trending signal\n",
    "        print(\"reverse=1\")\n",
    "        trend_signal_stat = get_signal_stat(signal_name, thre_mat, product, all_dates, CORE_NUM, split_str=split_str, reverse=1, \n",
    "                                    atr_filter=atr_filter, HEAD_PATH=HEAD_PATH, SAVE_PATH=SIGNAL_PATH)\n",
    "    if reverse<=0: ## reversal signal\n",
    "        print(\"reverse=-1\")\n",
    "        reverse_signal_stat = get_signal_stat(signal_name, thre_mat, product, all_dates, CORE_NUM, split_str=split_str, reverse=-1,\n",
    "                                            atr_filter=atr_filter, HEAD_PATH=HEAD_PATH, SAVE_PATH=SIGNAL_PATH)\n",
    "    if reverse==0: ## both trending and reversal\n",
    "        stat_result = OrderedDict([(\"trend.signal.stat\", trend_signal_stat), (\"reverse.signal.stat\", reverse_signal_stat)])    \n",
    "        save(stat_result, HEAD_PATH+\"/\"+save_path+\"/\"+product+\".\"+signal_name+\".pkl\")\n",
    "    elif reverse==1: ## just trend\n",
    "        save(trend_signal_stat, HEAD_PATH+\"/\"+save_path+\"/\"+product+\".\"+signal_name+\".trend.pkl\")\n",
    "    elif reverse==-1: ## just reversal\n",
    "        save(reverse_signal_stat, HEAD_PATH+\"/\"+save_path+\"/\"+product+\".\"+signal_name+\".reverse.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get the statistics of backtesting a signal\n",
    "from collections import OrderedDict\n",
    "def get_signal_stat(signal_name, thre_mat, product, all_dates, CORE_NUM, split_str=\"2018\", reverse=1, \n",
    "                     atr_filter=0, HEAD_PATH=\"d:/intern\", SAVE_PATH=\"d:/intern\"):\n",
    "    train_sample = all_dates<split_str ## training samples\n",
    "    test_sample = all_dates>split_str ## testing samples\n",
    "    with dask.config.set(scheduler='processes', num_workers=CORE_NUM):\n",
    "        f_par = functools.partial(get_signal_pnl, product=product, signal_name=signal_name, thre_mat=thre_mat,\n",
    "                                 reverse=1,\n",
    "                                HEAD_PATH=HEAD_PATH, SAVE_PATH=SAVE_PATH,atr_filter=atr_filter)\n",
    "        train_result = compute([delayed(f_par)(file) for file in all_dates[train_sample]])[0] ## get training result\n",
    "    train_stat = get_hft_summary(train_result, thre_mat) ## get training result statistics\n",
    "    with dask.config.set(scheduler='processes', num_workers=CORE_NUM):\n",
    "        f_par = functools.partial(get_signal_pnl, product=product, signal_name=signal_name, thre_mat=thre_mat,\n",
    "                                 reverse=1,\n",
    "                                HEAD_PATH=HEAD_PATH, SAVE_PATH=SAVE_PATH,atr_filter=atr_filter)\n",
    "        test_result = compute([delayed(f_par)(file) for file in all_dates[test_sample]])[0] ## get testing result\n",
    "    test_stat = get_hft_summary(test_result, thre_mat) ## get testing result statistics\n",
    "    return OrderedDict([(\"train.stat\", train_stat), (\"test.stat\", test_stat)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(HEAD_PATH+\"/signal result atr/\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600519 nr\n",
      "reverse=1\n",
      "reverse=-1\n",
      "600519 dbook\n",
      "reverse=1\n",
      "reverse=-1\n",
      "600519 range.pos\n",
      "reverse=1\n",
      "reverse=-1\n",
      "600519 price.osci\n",
      "reverse=1\n",
      "reverse=-1\n",
      "600519 ma.dif.10\n",
      "reverse=1\n",
      "reverse=-1\n",
      "600519 kdj.k\n",
      "reverse=1\n",
      "reverse=-1\n",
      "600519 kdj.j\n",
      "reverse=1\n",
      "reverse=-1\n",
      "600519 nr.range\n",
      "reverse=1\n",
      "reverse=-1\n",
      "600519 dbook.range\n",
      "reverse=1\n",
      "reverse=-1\n",
      "600519 range.pos.range\n",
      "reverse=1\n",
      "reverse=-1\n",
      "600519 price.osci.range\n",
      "reverse=1\n",
      "reverse=-1\n",
      "600519 ma.dif.10.range\n",
      "reverse=1\n",
      "reverse=-1\n",
      "600519 kdj.k.range\n",
      "reverse=1\n",
      "reverse=-1\n",
      "600519 kdj.j.range\n",
      "reverse=1\n",
      "reverse=-1\n",
      "600519 nr.std\n",
      "reverse=1\n",
      "reverse=-1\n",
      "600519 dbook.std\n",
      "reverse=1\n",
      "reverse=-1\n",
      "600519 range.pos.std\n",
      "reverse=1\n",
      "reverse=-1\n",
      "600519 price.osci.std\n",
      "reverse=1\n",
      "reverse=-1\n",
      "600519 ma.dif.10.std\n",
      "reverse=1\n",
      "reverse=-1\n",
      "600519 kdj.k.std\n",
      "reverse=1\n",
      "reverse=-1\n",
      "600519 kdj.j.std\n",
      "reverse=1\n",
      "reverse=-1\n",
      "600519 nr.trend.index\n",
      "reverse=1\n",
      "reverse=-1\n",
      "600519 dbook.trend.index\n",
      "reverse=1\n",
      "reverse=-1\n",
      "600519 range.pos.trend.index\n",
      "reverse=1\n",
      "reverse=-1\n",
      "600519 price.osci.trend.index\n",
      "reverse=1\n",
      "reverse=-1\n",
      "600519 ma.dif.10.trend.index\n",
      "reverse=1\n",
      "reverse=-1\n",
      "600519 kdj.k.trend.index\n",
      "reverse=1\n",
      "reverse=-1\n",
      "600519 kdj.j.trend.index\n",
      "reverse=1\n",
      "reverse=-1\n",
      "000858 nr\n",
      "reverse=1\n",
      "reverse=-1\n",
      "000858 dbook\n",
      "reverse=1\n",
      "reverse=-1\n",
      "000858 range.pos\n",
      "reverse=1\n",
      "reverse=-1\n",
      "000858 price.osci\n",
      "reverse=1\n",
      "reverse=-1\n",
      "000858 ma.dif.10\n",
      "reverse=1\n",
      "reverse=-1\n",
      "000858 kdj.k\n",
      "reverse=1\n",
      "reverse=-1\n",
      "000858 kdj.j\n",
      "reverse=1\n",
      "reverse=-1\n",
      "000858 nr.range\n",
      "reverse=1\n",
      "reverse=-1\n",
      "000858 dbook.range\n",
      "reverse=1\n",
      "reverse=-1\n",
      "000858 range.pos.range\n",
      "reverse=1\n",
      "reverse=-1\n",
      "000858 price.osci.range\n",
      "reverse=1\n",
      "reverse=-1\n",
      "000858 ma.dif.10.range\n",
      "reverse=1\n",
      "reverse=-1\n",
      "000858 kdj.k.range\n",
      "reverse=1\n",
      "reverse=-1\n",
      "000858 kdj.j.range\n",
      "reverse=1\n",
      "reverse=-1\n",
      "000858 nr.std\n",
      "reverse=1\n",
      "reverse=-1\n",
      "000858 dbook.std\n",
      "reverse=1\n",
      "reverse=-1\n",
      "000858 range.pos.std\n",
      "reverse=1\n",
      "reverse=-1\n",
      "000858 price.osci.std\n",
      "reverse=1\n",
      "reverse=-1\n",
      "000858 ma.dif.10.std\n",
      "reverse=1\n",
      "reverse=-1\n",
      "000858 kdj.k.std\n",
      "reverse=1\n",
      "reverse=-1\n",
      "000858 kdj.j.std\n",
      "reverse=1\n",
      "reverse=-1\n",
      "000858 nr.trend.index\n",
      "reverse=1\n",
      "reverse=-1\n",
      "000858 dbook.trend.index\n",
      "reverse=1\n",
      "reverse=-1\n",
      "000858 range.pos.trend.index\n",
      "reverse=1\n",
      "reverse=-1\n",
      "000858 price.osci.trend.index\n",
      "reverse=1\n",
      "reverse=-1\n",
      "000858 ma.dif.10.trend.index\n",
      "reverse=1\n",
      "reverse=-1\n",
      "000858 kdj.k.trend.index\n",
      "reverse=1\n",
      "reverse=-1\n",
      "000858 kdj.j.trend.index\n",
      "reverse=1\n",
      "reverse=-1\n",
      "000568 nr\n",
      "reverse=1\n",
      "reverse=-1\n",
      "000568 dbook\n",
      "reverse=1\n",
      "reverse=-1\n",
      "000568 range.pos\n",
      "reverse=1\n",
      "reverse=-1\n",
      "000568 price.osci\n",
      "reverse=1\n",
      "reverse=-1\n",
      "000568 ma.dif.10\n",
      "reverse=1\n",
      "reverse=-1\n",
      "000568 kdj.k\n",
      "reverse=1\n",
      "reverse=-1\n",
      "000568 kdj.j\n",
      "reverse=1\n",
      "reverse=-1\n",
      "000568 nr.range\n",
      "reverse=1\n",
      "reverse=-1\n",
      "000568 dbook.range\n",
      "reverse=1\n",
      "reverse=-1\n",
      "000568 range.pos.range\n",
      "reverse=1\n",
      "reverse=-1\n",
      "000568 price.osci.range\n",
      "reverse=1\n",
      "reverse=-1\n",
      "000568 ma.dif.10.range\n",
      "reverse=1\n",
      "reverse=-1\n",
      "000568 kdj.k.range\n",
      "reverse=1\n",
      "reverse=-1\n",
      "000568 kdj.j.range\n",
      "reverse=1\n",
      "reverse=-1\n",
      "000568 nr.std\n",
      "reverse=1\n",
      "reverse=-1\n",
      "000568 dbook.std\n",
      "reverse=1\n",
      "reverse=-1\n",
      "000568 range.pos.std\n",
      "reverse=1\n",
      "reverse=-1\n",
      "000568 price.osci.std\n",
      "reverse=1\n",
      "reverse=-1\n",
      "000568 ma.dif.10.std\n",
      "reverse=1\n",
      "reverse=-1\n",
      "000568 kdj.k.std\n",
      "reverse=1\n",
      "reverse=-1\n",
      "000568 kdj.j.std\n",
      "reverse=1\n",
      "reverse=-1\n",
      "000568 nr.trend.index\n",
      "reverse=1\n",
      "reverse=-1\n",
      "000568 dbook.trend.index\n",
      "reverse=1\n",
      "reverse=-1\n",
      "000568 range.pos.trend.index\n",
      "reverse=1\n",
      "reverse=-1\n",
      "000568 price.osci.trend.index\n",
      "reverse=1\n",
      "reverse=-1\n",
      "000568 ma.dif.10.trend.index\n",
      "reverse=1\n",
      "reverse=-1\n",
      "000568 kdj.k.trend.index\n",
      "reverse=1\n",
      "reverse=-1\n",
      "000568 kdj.j.trend.index\n",
      "reverse=1\n",
      "reverse=-1\n",
      "600809 nr\n",
      "reverse=1\n",
      "reverse=-1\n",
      "600809 dbook\n",
      "reverse=1\n",
      "reverse=-1\n",
      "600809 range.pos\n",
      "reverse=1\n",
      "reverse=-1\n",
      "600809 price.osci\n",
      "reverse=1\n",
      "reverse=-1\n",
      "600809 ma.dif.10\n",
      "reverse=1\n",
      "reverse=-1\n",
      "600809 kdj.k\n",
      "reverse=1\n",
      "reverse=-1\n",
      "600809 kdj.j\n",
      "reverse=1\n",
      "reverse=-1\n",
      "600809 nr.range\n",
      "reverse=1\n",
      "reverse=-1\n",
      "600809 dbook.range\n",
      "reverse=1\n",
      "reverse=-1\n",
      "600809 range.pos.range\n",
      "reverse=1\n",
      "reverse=-1\n",
      "600809 price.osci.range\n",
      "reverse=1\n",
      "reverse=-1\n",
      "600809 ma.dif.10.range\n",
      "reverse=1\n",
      "reverse=-1\n",
      "600809 kdj.k.range\n",
      "reverse=1\n",
      "reverse=-1\n",
      "600809 kdj.j.range\n",
      "reverse=1\n",
      "reverse=-1\n",
      "600809 nr.std\n",
      "reverse=1\n",
      "reverse=-1\n",
      "600809 dbook.std\n",
      "reverse=1\n",
      "reverse=-1\n",
      "600809 range.pos.std\n",
      "reverse=1\n",
      "reverse=-1\n",
      "600809 price.osci.std\n",
      "reverse=1\n",
      "reverse=-1\n",
      "600809 ma.dif.10.std\n",
      "reverse=1\n",
      "reverse=-1\n",
      "600809 kdj.k.std\n",
      "reverse=1\n",
      "reverse=-1\n",
      "600809 kdj.j.std\n",
      "reverse=1\n",
      "reverse=-1\n",
      "600809 nr.trend.index\n",
      "reverse=1\n",
      "reverse=-1\n",
      "600809 dbook.trend.index\n",
      "reverse=1\n",
      "reverse=-1\n",
      "600809 range.pos.trend.index\n",
      "reverse=1\n",
      "reverse=-1\n",
      "600809 price.osci.trend.index\n",
      "reverse=1\n",
      "reverse=-1\n",
      "600809 ma.dif.10.trend.index\n",
      "reverse=1\n",
      "reverse=-1\n",
      "600809 kdj.k.trend.index\n",
      "reverse=1\n",
      "reverse=-1\n",
      "600809 kdj.j.trend.index\n",
      "reverse=1\n",
      "reverse=-1\n",
      "002304 nr\n",
      "reverse=1\n",
      "reverse=-1\n",
      "002304 dbook\n",
      "reverse=1\n",
      "reverse=-1\n",
      "002304 range.pos\n",
      "reverse=1\n",
      "reverse=-1\n",
      "002304 price.osci\n",
      "reverse=1\n",
      "reverse=-1\n",
      "002304 ma.dif.10\n",
      "reverse=1\n",
      "reverse=-1\n",
      "002304 kdj.k\n",
      "reverse=1\n",
      "reverse=-1\n",
      "002304 kdj.j\n",
      "reverse=1\n",
      "reverse=-1\n",
      "002304 nr.range\n",
      "reverse=1\n",
      "reverse=-1\n",
      "002304 dbook.range\n",
      "reverse=1\n",
      "reverse=-1\n",
      "002304 range.pos.range\n",
      "reverse=1\n",
      "reverse=-1\n",
      "002304 price.osci.range\n",
      "reverse=1\n",
      "reverse=-1\n",
      "002304 ma.dif.10.range\n",
      "reverse=1\n",
      "reverse=-1\n",
      "002304 kdj.k.range\n",
      "reverse=1\n",
      "reverse=-1\n",
      "002304 kdj.j.range\n",
      "reverse=1\n",
      "reverse=-1\n",
      "002304 nr.std\n",
      "reverse=1\n",
      "reverse=-1\n",
      "002304 dbook.std\n",
      "reverse=1\n",
      "reverse=-1\n",
      "002304 range.pos.std\n",
      "reverse=1\n",
      "reverse=-1\n",
      "002304 price.osci.std\n",
      "reverse=1\n",
      "reverse=-1\n",
      "002304 ma.dif.10.std\n",
      "reverse=1\n",
      "reverse=-1\n",
      "002304 kdj.k.std\n",
      "reverse=1\n",
      "reverse=-1\n",
      "002304 kdj.j.std\n",
      "reverse=1\n",
      "reverse=-1\n",
      "002304 nr.trend.index\n",
      "reverse=1\n",
      "reverse=-1\n",
      "002304 dbook.trend.index\n",
      "reverse=1\n",
      "reverse=-1\n",
      "002304 range.pos.trend.index\n",
      "reverse=1\n",
      "reverse=-1\n",
      "002304 price.osci.trend.index\n",
      "reverse=1\n",
      "reverse=-1\n",
      "002304 ma.dif.10.trend.index\n",
      "reverse=1\n",
      "reverse=-1\n",
      "002304 kdj.k.trend.index\n",
      "reverse=1\n",
      "reverse=-1\n",
      "002304 kdj.j.trend.index\n",
      "reverse=1\n",
      "reverse=-1\n",
      "CPU times: user 30.8 s, sys: 24.2 s, total: 55 s\n",
      "Wall time: 15h 7min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#SIGNAL_PATH = \"e:/intern\"\n",
    "for product in product_list:\n",
    "    all_dates = np.array(os.listdir(DATA_PATH + product))\n",
    "    for signal in all_signal_list:\n",
    "        print(product, signal)\n",
    "        evaluate_signal(signal, all_dates, product, 0.001, 20, CORE_NUM, HEAD_PATH, SAVE_PATH,\n",
    "                        period=4096, split_str=\"2017\",\n",
    "            atr_filter=0.02, save_path=\"signal result atr\")\n",
    "\n",
    "## Wall time: 14h 53min 10s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- we can write a function to get all the signals' performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- we can get the result with atr and without atr separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get the signal performance\n",
    "## including trend and reverse signals\n",
    "def get_signal_performance_result(all_period_signal, signal_dire, period, product_list):\n",
    "    trend_signal_result = pd.DataFrame(data=OrderedDict([(\"signal\", all_period_signal), (\"reverse\",1),\n",
    "                               (\"num\", 0), (\"trainSharpe\", 0), (\"testSharpe\", 0)]))\n",
    "    reverse_signal_result = pd.DataFrame(data=OrderedDict([(\"signal\", all_period_signal), (\"reverse\",-1),\n",
    "                               (\"num\", 0), (\"trainSharpe\", 0), (\"testSharpe\", 0)]))\n",
    "    n_signal = len(all_period_signal) ## number of all signals\n",
    "    trend_train_sharpe = np.zeros(len(product_list))\n",
    "    trend_test_sharpe = np.zeros(len(product_list))\n",
    "    reverse_train_sharpe = np.zeros(len(product_list))\n",
    "    reverse_test_sharpe = np.zeros(len(product_list))\n",
    "    avg_pnl = 0.001\n",
    "    for k in range(n_signal):\n",
    "        signal_name = all_period_signal[k]\n",
    "        i = 0\n",
    "        for product in product_list:\n",
    "            all_dates = np.array(os.listdir(DATA_PATH + product))\n",
    "            train_sample = all_dates<\"2019\" \n",
    "            test_sample = all_dates>\"2019\"\n",
    "            stat_result = load(HEAD_PATH+\"/\" + signal_dire +\"/\"+product+\".\"+signal_name+\".pkl\") ## statistics of signal over a product\n",
    "            trend_signal_stat = stat_result['trend.signal.stat'] ## trending statistics\n",
    "            \n",
    "            if tuple(trend_signal_stat.keys())[0]=='train.stat':\n",
    "                train_stat = trend_signal_stat[\"train.stat\"]\n",
    "                test_stat = trend_signal_stat[\"test.stat\"]\n",
    "                #good_strat = trend_signal_stat[\"good.strat\"]\n",
    "                good_strat = (train_stat[\"final.result\"][\"avg.ret\"]>avg_pnl) & (train_stat[\"final.result\"][\"num\"]>10)\n",
    "                if sum(good_strat)>2:\n",
    "                    train_stat = trend_signal_stat[\"train.stat\"]\n",
    "                    test_stat = trend_signal_stat[\"test.stat\"]\n",
    "                    train_pnl = train_stat[\"daily.pnl\"][:, good_strat].sum(axis=1)/sum(good_strat)\n",
    "                    #train_std = np.std(train_pnl)\n",
    "                    #train_pnl = train_pnl/train_std\n",
    "                    test_pnl = test_stat[\"daily.pnl\"][:, good_strat].sum(axis=1)/sum(good_strat)\n",
    "                    trend_train_sharpe[i] = sharpe(train_pnl)\n",
    "                    trend_test_sharpe[i] = sharpe(test_pnl)\n",
    "                    #print(product, \"train sharpe \", sharpe(train_pnl), \"test sharpe \", sharpe(test_pnl))\n",
    "                    i = i+1\n",
    "            if i>0: ## if there are any good products\n",
    "                trend_signal_result.loc[k, (\"signal\", \"num\", \"trainSharpe\", \"testSharpe\")] = (signal_name, i,  np.mean(trend_train_sharpe[:i]),np.mean(trend_test_sharpe[:i]))\n",
    "        i = 0\n",
    "        for product in product_list:\n",
    "            stat_result = load(HEAD_PATH+\"/\"+signal_dire+\"/\"+product+\".\"+signal_name+\".pkl\")\n",
    "            reverse_signal_stat = stat_result['reverse.signal.stat']\n",
    "            if tuple(reverse_signal_stat.keys())[0]=='train.stat':\n",
    "                #good_strat = reverse_signal_stat[\"good.strat\"]\n",
    "                train_stat = reverse_signal_stat[\"train.stat\"]\n",
    "                train_pnl = train_stat[\"daily.pnl\"][:, good_strat].sum(axis=1)/sum(good_strat)\n",
    "                test_stat = reverse_signal_stat[\"test.stat\"]\n",
    "                good_strat = (train_stat[\"final.result\"][\"avg.ret\"]>avg_pnl) & (train_stat[\"final.result\"][\"num\"]>10)\n",
    "                test_pnl = test_stat[\"daily.pnl\"][:, good_strat].sum(axis=1)/sum(good_strat)\n",
    "                if sum(good_strat)>2:\n",
    "                    #train_std = np.std(train_pnl)\n",
    "                    #train_pnl = train_pnl/train_std\n",
    "                    reverse_train_sharpe[i] = sharpe(train_pnl)\n",
    "                    reverse_test_sharpe[i] = sharpe(test_pnl)\n",
    "                    i = i+1\n",
    "            if i>0:\n",
    "                \n",
    "                reverse_signal_result.loc[k, (\"signal\",\"num\", \"trainSharpe\", \"testSharpe\")] = (signal_name, i, np.mean(reverse_train_sharpe[:i]),np.mean(reverse_test_sharpe[:i]))\n",
    "    return OrderedDict([(\"trend.signal.stat\", trend_signal_result), \n",
    "                        (\"reverse.signal.stat\", reverse_signal_result)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_atr = get_signal_performance_result(all_period_signal, \"signal result atr\", 4096, product_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_single_signal_stat(result_atr, min_num=0, min_sharpe=0.5):\n",
    "    good_trend = (result_atr[\"trend.signal.stat\"][\"num\"]>min_num) & (result_atr[\"trend.signal.stat\"][\"trainSharpe\"]>min_sharpe) & (result_atr[\"trend.signal.stat\"][\"testSharpe\"]>min_sharpe)\n",
    "    good_reverse = (result_atr[\"reverse.signal.stat\"][\"num\"]>min_num) & (result_atr[\"reverse.signal.stat\"][\"trainSharpe\"]>min_sharpe) & (result_atr[\"reverse.signal.stat\"][\"testSharpe\"]>min_sharpe)\n",
    "    print(\"with atr good signals: \"+ str(sum(good_trend | good_reverse)))\n",
    "    train_sharpe = np.mean(np.append(result_atr[\"trend.signal.stat\"][\"trainSharpe\"][good_trend],\n",
    "                      result_atr[\"reverse.signal.stat\"][\"trainSharpe\"][good_reverse]))\n",
    "    test_sharpe = np.mean(np.append(result_atr[\"trend.signal.stat\"][\"testSharpe\"][good_trend],\n",
    "                      result_atr[\"reverse.signal.stat\"][\"testSharpe\"][good_reverse]))\n",
    "    print(\"train sharpe: \", train_sharpe)\n",
    "    print(\"test sharpe: \", test_sharpe)\n",
    "    print(all_signal_list[good_trend])\n",
    "    print(all_signal_list[good_reverse])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with atr good signals: 7\n",
      "train sharpe:  0.25031657008063096\n",
      "test sharpe:  0.3381809954027074\n",
      "['nr' 'price.osci' 'kdj.k' 'kdj.j' 'nr.trend.index'\n",
      " 'range.pos.trend.index' 'price.osci.trend.index']\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "get_single_signal_stat(result_atr, min_num=0, min_sharpe=0)\n",
    "\n",
    "# with atr good signals: 7\n",
    "# train sharpe:  0.25031657008063096\n",
    "# test sharpe:  0.3381809954027074\n",
    "# ['nr' 'price.osci' 'kdj.k' 'kdj.j' 'nr.trend.index'\n",
    "#  'range.pos.trend.index' 'price.osci.trend.index']\n",
    "# []\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with atr good signals: 6\n",
      "train sharpe:  0.232794205322825\n",
      "test sharpe:  0.335934275190708\n",
      "['nr' 'price.osci' 'kdj.k' 'nr.trend.index' 'range.pos.trend.index'\n",
      " 'price.osci.trend.index']\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "get_single_signal_stat(result_atr, min_num=1, min_sharpe=0)\n",
    "\n",
    "# with atr good signals: 6\n",
    "# train sharpe:  0.232794205322825\n",
    "# test sharpe:  0.335934275190708\n",
    "# ['nr' 'price.osci' 'kdj.k' 'nr.trend.index' 'range.pos.trend.index'\n",
    "#  'price.osci.trend.index']\n",
    "# []\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with atr good signals: 4\n",
      "train sharpe:  0.22417098533953134\n",
      "test sharpe:  0.2856700020721965\n",
      "['kdj.k' 'nr.trend.index' 'range.pos.trend.index' 'price.osci.trend.index']\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "get_single_signal_stat(result_atr, min_num=2, min_sharpe=0)\n",
    "\n",
    "# with atr good signals: 4\n",
    "# train sharpe:  0.22417098533953134\n",
    "# test sharpe:  0.2856700020721965\n",
    "# ['kdj.k' 'nr.trend.index' 'range.pos.trend.index' 'price.osci.trend.index']\n",
    "# []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with atr good signals: 1\n",
      "train sharpe:  0.21218760742128087\n",
      "test sharpe:  0.487643784373875\n",
      "['price.osci.trend.index']\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "get_single_signal_stat(result_atr, min_num=3, min_sharpe=0)\n",
    "\n",
    "# with atr good signals: 1\n",
    "# train sharpe:  0.21218760742128087\n",
    "# test sharpe:  0.487643784373875\n",
    "# ['price.osci.trend.index']\n",
    "# []\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with atr good signals: 1\n",
      "train sharpe:  0.21218760742128087\n",
      "test sharpe:  0.487643784373875\n",
      "['price.osci.trend.index']\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "get_single_signal_stat(result_atr, min_num=4, min_sharpe=0)\n",
    "\n",
    "# with atr good signals: 1\n",
    "# train sharpe:  0.21218760742128087\n",
    "# test sharpe:  0.487643784373875\n",
    "# ['price.osci.trend.index']\n",
    "# []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- we can see that their results are very similar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Conclusion\n",
    "- This week we have generated results for all of the 35 signals\n",
    "- We have compared backtest result with and without atr\n",
    "- we find that there is not much difference between them\n",
    "- previously we found that for iorn with atr is better than without atr\n",
    "- that's because we lower the threhsold for number of trades\n",
    "- now we use 20 trades for training maybe for i there are not enough trades\n",
    "- Anyway, currently there are too many signals and hard to tune parameters\n",
    "- in the future, we can use fewer signals so that we can do the research more efficiently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
