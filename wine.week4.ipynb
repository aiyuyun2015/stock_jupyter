{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEAD_PATH = './'\n",
    "DATA_PATH = HEAD_PATH + \"data/stocks/\"\n",
    "SAVE_PATH = HEAD_PATH + \"ckpt/\"\n",
    "TEMP_PATH = SAVE_PATH + \"tmp pkl/\"\n",
    "OUTPUT_PATH = HEAD_PATH + 'output'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Welcome to Quantitative and High Frequency Trading Training Program\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'stock_stats' from '/Users/junsu/Dropbox/workspace/stock_official/stock_stats.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from stock_helper import *\n",
    "from stock_stats import *\n",
    "from imp import reload  \n",
    "import stock_helper\n",
    "import stock_stats\n",
    "reload(stock_helper)\n",
    "reload(stock_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function stock_helper.get_signal_pnl(file, product, signal_name, thre_mat, reverse=1, tranct=0.00011, max_spread=0.61, tranct_ratio=True, HEAD_PATH='d:/intern', SAVE_PATH='d:/intern', atr_filter=0, rebate=0)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_signal_pnl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    " \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- number of cores, set this number according to your computer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CORE_NUM = int(os.environ['NUMBER_OF_PROCESSORS'])\n",
    "CORE_NUM =11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- sample product, you can change to your specific product symbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_list = [\"600519\", \"000858\", \"000568\", \"600809\", \"002304\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "from dask import compute, delayed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- sample period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "period = 4096\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_dates = os.listdir(DATA_PATH + product_list[0])\n",
    "all_dates.sort()\n",
    "all_dates = np.array(all_dates)\n",
    "n_days = len(all_dates)\n",
    "n_days\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- choose an example day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sample = all_dates<\"2017\"\n",
    "\n",
    "test_sample = all_dates>\"2017\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- at last we plot the selected pnl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- now we can see that the number of signals are not very big\n",
    "- and the quality is not so good\n",
    "- we can propose a systematic method to generate a large number of signals then\n",
    "- we can choose good ones from them\n",
    "\n",
    "- for example, we can first generate some signals about volatility without direction\n",
    "- there are some ideas about it\n",
    "\n",
    "- standard deviation\n",
    "- range of price\n",
    "- ratio of volume to turnover\n",
    "\n",
    "- then we can generate some signals with direction\n",
    "- actually all of our previous signals have direction\n",
    "- but some of them are good and some of them are bad\n",
    "- we can focus on some good and simple ones, such as\n",
    "\n",
    "- normalized return\n",
    "- rsi\n",
    "- dbook\n",
    "\n",
    "- let's try to generate range signals first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## calculate rolling standard deviation\n",
    "from collections import OrderedDict\n",
    "class foctor_std_period(factor_template):\n",
    "    factor_name = \"std.period\"\n",
    "    \n",
    "    params = OrderedDict([\n",
    "        (\"period\", np.power(2, range(12,13)))\n",
    "    ])\n",
    "    \n",
    "    def formula(self, data, period):\n",
    "        return np.sqrt(fast_roll_var(data[\"wpr\"], period))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## calcualte rolling variance\n",
    "def fast_roll_var(x, period):\n",
    "    x_ma = cum(x,period)/period ## roling first moment\n",
    "    x2 = x*x\n",
    "    x2_ma = cum(x2,period)/period ## rolling second moment\n",
    "    var_x = x2_ma-x_ma*x_ma ## rolling variance\n",
    "    return(var_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./ckpt//tmp pkl/600519/std.4096\n",
      "./ckpt//tmp pkl/000858/std.4096\n",
      "./ckpt//tmp pkl/000568/std.4096\n",
      "./ckpt//tmp pkl/600809/std.4096\n",
      "./ckpt//tmp pkl/002304/std.4096\n"
     ]
    }
   ],
   "source": [
    "x20 = foctor_std_period()\n",
    "for product in product_list:\n",
    "    create_signal_path(x20, product, SAVE_PATH);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 198 ms, sys: 224 ms, total: 422 ms\n",
      "Wall time: 25.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for product in product_list:\n",
    "    file_list = list(map(lambda x: DATA_PATH+product+\"/\"+x, sorted(os.listdir(DATA_PATH + product))))\n",
    "    parLapply(CORE_NUM, file_list, build_composite_signal,signal_list=x20, product=product, HEAD_PATH=SAVE_PATH, n=8)\n",
    "    \n",
    "# Wall time: 1min 47s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## rolling price range\n",
    "from collections import OrderedDict\n",
    "class foctor_range_period(factor_template):\n",
    "    factor_name = \"range.period\"\n",
    "    \n",
    "    params = OrderedDict([\n",
    "        (\"period\", np.power(2, range(12,13)))\n",
    "    ])\n",
    "    \n",
    "    def formula(self, data, period):\n",
    "        return data[\"max.\"+str(period)]-data[\"min.\"+str(period)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./ckpt//tmp pkl/600519/range.4096\n",
      "./ckpt//tmp pkl/000858/range.4096\n",
      "./ckpt//tmp pkl/000568/range.4096\n",
      "./ckpt//tmp pkl/600809/range.4096\n",
      "./ckpt//tmp pkl/002304/range.4096\n"
     ]
    }
   ],
   "source": [
    "x21 = foctor_range_period()\n",
    "for product in product_list:\n",
    "    create_signal_path(x21, product, SAVE_PATH);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 144 ms, sys: 200 ms, total: 344 ms\n",
      "Wall time: 23.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for product in product_list:\n",
    "    file_list = list(map(lambda x: DATA_PATH+product+\"/\"+x, sorted(os.listdir(DATA_PATH + product))))\n",
    "    parLapply(CORE_NUM, file_list, build_composite_signal,signal_list=x21, product=product, HEAD_PATH=SAVE_PATH, n=8)\n",
    "    \n",
    "## Wall time: 1min 8s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## rolling trend index\n",
    "from collections import OrderedDict\n",
    "class foctor_trend_index_period(factor_template):\n",
    "    factor_name = \"trend.index.period\"\n",
    "    \n",
    "    params = OrderedDict([\n",
    "        (\"period\", np.power(2, range(12,13)))\n",
    "    ])\n",
    "    \n",
    "    def formula(self, data, period):\n",
    "        aa = zero_divide(abs(data[\"wpr\"]-data[\"wpr\"].shift(period)), data[\"max.\"+str(period)]-data[\"min.\"+str(period)])\n",
    "        aa[0:period]=0\n",
    "        return aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./ckpt//tmp pkl/600519/trend.index.4096\n",
      "./ckpt//tmp pkl/000858/trend.index.4096\n",
      "./ckpt//tmp pkl/000568/trend.index.4096\n",
      "./ckpt//tmp pkl/600809/trend.index.4096\n",
      "./ckpt//tmp pkl/002304/trend.index.4096\n"
     ]
    }
   ],
   "source": [
    "x23 = foctor_trend_index_period()\n",
    "for product in product_list:\n",
    "    create_signal_path(x23, product, SAVE_PATH);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Then we construt these range signals "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 196 ms, sys: 221 ms, total: 417 ms\n",
      "Wall time: 25 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "for product in product_list:\n",
    "    file_list = list(map(lambda x: DATA_PATH+product+\"/\"+x, sorted(os.listdir(DATA_PATH + product))))\n",
    "    parLapply(CORE_NUM, file_list, build_composite_signal,signal_list=x20, product=product, HEAD_PATH=SAVE_PATH, n=8)\n",
    ";\n",
    "# Wall time: 1min 11s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 195 ms, sys: 210 ms, total: 405 ms\n",
      "Wall time: 25.4 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "for product in product_list:\n",
    "    file_list = list(map(lambda x: DATA_PATH+product+\"/\"+x, sorted(os.listdir(DATA_PATH + product))))\n",
    "    parLapply(CORE_NUM, file_list, build_composite_signal,signal_list=x23, product=product, HEAD_PATH=SAVE_PATH,n=8)\n",
    ";\n",
    "\n",
    "## Wall time: 1min 14s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now we can combine directional signals and range signals together to become new direction signals\n",
    "\n",
    "- For example, we have n directional signals, and m range signals, \n",
    "- then we can generate new n*m directional signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## generate composite signal: trend signal * range signal = new trend signal\n",
    "def construct_composite_signal(dire_signal, range_signal, period_list, product_list, HEAD_PATH):\n",
    "    from collections import OrderedDict\n",
    "    class foctor_xx_period(factor_template):\n",
    "        factor_name = dire_signal+\".\"+range_signal+\".period\" ## name of new signal\n",
    "        params = OrderedDict([\n",
    "            (\"period\", period_list)\n",
    "        ])\n",
    "        def formula(self, data, period):\n",
    "            return (data[dire_signal+\".\"+str(period)]*data[range_signal+\".\"+str(period)]).values ## calculation of new signal\n",
    "    xx = foctor_xx_period()\n",
    "    for product in product_list:\n",
    "        create_signal_path(xx, product, HEAD_PATH)\n",
    "        file_list = list(map(lambda x: DATA_PATH+product+\"/\"+x, sorted(os.listdir(DATA_PATH + product))))\n",
    "        parLapply(CORE_NUM, file_list, build_composite_signal,signal_list=xx, product=product, HEAD_PATH=HEAD_PATH,n=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## generate composite signal: trend signal * range signal = new trend signal\n",
    "def construct_composite_signal(dire_signal, range_signal, period_list, product_list, HEAD_PATH):\n",
    "    from collections import OrderedDict\n",
    "    class foctor_xx_period(factor_template):\n",
    "        factor_name = dire_signal+\".\"+range_signal+\".period\" ## name of new signal\n",
    "        params = OrderedDict([\n",
    "            (\"period\", period_list)\n",
    "        ])\n",
    "        def formula(self, data, period):\n",
    "            return (data[dire_signal+\".\"+str(period)]*data[range_signal+\".\"+str(period)]).values ## calculation of new signal\n",
    "    xx = foctor_xx_period()\n",
    "    for product in product_list:\n",
    "        create_signal_path(xx, product, HEAD_PATH)\n",
    "        file_list = list(map(lambda x: DATA_PATH+product+\"/\"+x, sorted(os.listdir(DATA_PATH + product))))\n",
    "        parLapply(CORE_NUM, file_list, build_composite_signal,signal_list=xx, product=product, HEAD_PATH=HEAD_PATH,n=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dire_signal_list = [\"nr\", \"dbook\", \"range.pos\", \"price.osci\", \"ma.dif.10\", \"kdj.k\", \"kdj.j\"]\n",
    "range_signal_list = [\"range\", \"std\", \"trend.index\"]\n",
    "period_list = np.power(2, range(12,13))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./ckpt//tmp pkl/600519/nr.range.4096\n",
      "./ckpt//tmp pkl/000858/nr.range.4096\n",
      "./ckpt//tmp pkl/000568/nr.range.4096\n",
      "./ckpt//tmp pkl/600809/nr.range.4096\n",
      "./ckpt//tmp pkl/002304/nr.range.4096\n",
      "./ckpt//tmp pkl/600519/dbook.range.4096\n",
      "./ckpt//tmp pkl/000858/dbook.range.4096\n",
      "./ckpt//tmp pkl/000568/dbook.range.4096\n",
      "./ckpt//tmp pkl/600809/dbook.range.4096\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-5c3a6586c39c>\u001b[0m in \u001b[0;36mconstruct_composite_signal\u001b[0;34m(dire_signal, range_signal, period_list, product_list, HEAD_PATH)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mcreate_signal_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproduct\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHEAD_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mfile_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDATA_PATH\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mproduct\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_PATH\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mproduct\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mparLapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCORE_NUM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_composite_signal\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msignal_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproduct\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproduct\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHEAD_PATH\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mHEAD_PATH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Dropbox/workspace/stock_official/stock_helper.py\u001b[0m in \u001b[0;36mparLapply\u001b[0;34m(CORE_NUM, iterable, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mdask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'processes'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCORE_NUM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mf_par\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdelayed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf_par\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dask/base.py\u001b[0m in \u001b[0;36mcompute\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    563\u001b[0m         \u001b[0mpostcomputes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dask_postcompute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 565\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mschedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdsk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    566\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrepack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostcomputes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dask/multiprocessing.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(dsk, keys, num_workers, func_loads, func_dumps, optimize_graph, pool, **kwargs)\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0;31m# Run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m         result = get_async(\n\u001b[0m\u001b[1;32m    221\u001b[0m             \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m             \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dask/local.py\u001b[0m in \u001b[0;36mget_async\u001b[0;34m(apply_async, num_workers, dsk, result, cache, get_id, rerun_exceptions_locally, pack_exception, raise_exception, callbacks, dumps, loads, **kwargs)\u001b[0m\n\u001b[1;32m    474\u001b[0m             \u001b[0;31m# Main loop, wait on tasks to finish, insert new ones\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"waiting\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ready\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"running\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 476\u001b[0;31m                 \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfailed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mqueue_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    477\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mfailed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m                     \u001b[0mexc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/dask/local.py\u001b[0m in \u001b[0;36mqueue_get\u001b[0;34m(q)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mqueue_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_qsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"'timeout' must be a non-negative number\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for range_signal in range_signal_list:\n",
    "    for dire_signal in dire_signal_list:\n",
    "        construct_composite_signal(dire_signal, range_signal, period_list, product_list, SAVE_PATH)\n",
    "##ã€€Wall time: 25min 19s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now we can combine signals of each day in to a vector\n",
    "- here we use 4096 as period\n",
    "- so to keep them independent, we choose 1 out of every 4096 points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "period = 4096\n",
    "os.makedirs(HEAD_PATH+\"/all signal\", exist_ok=True)\n",
    "dire_signal_list = [\"nr\", \"dbook\", \"range.pos\", \"price.osci\", \"ma.dif.10\", \"kdj.k\", \"kdj.j\"]\n",
    "range_signal_list = [\"\", \"range\", \"std\", \"trend.index\"]\n",
    "all_signal_list = np.array([])\n",
    "for range_signal in range_signal_list:\n",
    "    for dire_signal in dire_signal_list:\n",
    "        if len(range_signal)==0:\n",
    "            signal_name = dire_signal\n",
    "        else:\n",
    "            signal_name = dire_signal+\".\"+range_signal\n",
    "        all_signal_list = np.append(all_signal_list,signal_name)\n",
    "all_period_signal = [signal+\".4096\" for signal in all_signal_list]\n",
    "len(all_period_signal)\n",
    "## 28"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- we have 9 directional (trend) signals and 4 range signals\n",
    "- so we have 36 composite signals \n",
    "- plus the 9 original ones we have 45 signals together\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_average(a, n=3) :\n",
    "    ret_sum = np.cumsum(a, dtype=float)\n",
    "    ret = a\n",
    "    ret[n:] = (ret_sum[n:] - ret_sum[:-n])/n\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "## parallel generate the distribution of a signal\n",
    "def par_get_all_signal(signal_name, file_list, product, period, HEAD_PATH=\"d:/intern\", SAVE_PATH=\"e:/intern\", DATA_PATH=\"d:/intern\"):\n",
    "    n_files = len(file_list)\n",
    "    all_signal = np.array([])\n",
    "    for file in file_list:\n",
    "        signal = load(HEAD_PATH+\"/tmp pkl/\"+product+\"/\"+signal_name+\"/\"+file) ## signal\n",
    "        #moving_average(signal,period)\n",
    "        chosen = (np.arange(len(signal))+1) % period==0\n",
    "        all_signal = np.concatenate((all_signal, signal[chosen]), axis=0)\n",
    "    save(all_signal, SAVE_PATH+\"/all signal/\"+product+\".\"+signal_name+\".pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 28.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for product in product_list:\n",
    "    all_dates = os.listdir(DATA_PATH + product)\n",
    "    parLapply(CORE_NUM, all_period_signal, par_get_all_signal, file_list=all_dates, product=product, period=4096, HEAD_PATH=SAVE_PATH,\n",
    "             SAVE_PATH = \"e:/intern\", DATA_PATH=\"e:/intern\");\n",
    "## Wall time: 28.5 s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- then we can backtest our signals \n",
    "- we save the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "## this is to evalute the performance of a signal on a product\n",
    "def evaluate_signal(signal, all_dates, product, min_pnl, min_num, \n",
    "                    CORE_NUM, HEAD_PATH=\"d:/intern\", SIGNAL_PATH=\"d:/intern\", period=4096, split_str=\"2018\", \n",
    "                    atr_filter=0, save_path=\"signal result\",reverse=0):\n",
    "    signal_name = signal+\".\"+str(period) ## signal name, with period\n",
    "    all_signal = load(SIGNAL_PATH+\"/all signal/\"+product+\".\"+signal_name+\".pkl\") ## get the distribution of the signal\n",
    "    open_list = np.quantile(abs(all_signal), np.append(np.arange(0.991,0.999,0.001),np.arange(0.9991,0.9999,0.0001))) ## open threshold\n",
    "    thre_list = []\n",
    "    for cartesian in itertools.product(open_list, np.array([0.2, 0.4, 0.6, 0.8, 1.0])): ## close threshold\n",
    "        thre_list.append((cartesian[0], -cartesian[0] * cartesian[1]))\n",
    "    thre_list = np.array(thre_list)\n",
    "    thre_mat = pd.DataFrame(data=OrderedDict([(\"open\", thre_list[:, 0]), (\"close\", thre_list[:, 1])])) ## threshold matrix\n",
    "    \n",
    "    if reverse>=0: ## trending signal\n",
    "        print(\"reverse=1\")\n",
    "        trend_signal_stat = get_signal_stat(signal_name, thre_mat, product, all_dates, CORE_NUM, split_str=split_str, reverse=1, \n",
    "                                    atr_filter=atr_filter, HEAD_PATH=HEAD_PATH, SAVE_PATH=SIGNAL_PATH)\n",
    "    if reverse<=0: ## reversal signal\n",
    "        print(\"reverse=-1\")\n",
    "        reverse_signal_stat = get_signal_stat(signal_name, thre_mat, product, all_dates, CORE_NUM, split_str=split_str, reverse=-1,\n",
    "                                            atr_filter=atr_filter, HEAD_PATH=HEAD_PATH, SAVE_PATH=SIGNAL_PATH)\n",
    "    if reverse==0: ## both trending and reversal\n",
    "        stat_result = OrderedDict([(\"trend.signal.stat\", trend_signal_stat), (\"reverse.signal.stat\", reverse_signal_stat)])    \n",
    "        save(stat_result, HEAD_PATH+\"/\"+save_path+\"/\"+product+\".\"+signal_name+\".pkl\")\n",
    "    elif reverse==1: ## just trend\n",
    "        save(trend_signal_stat, HEAD_PATH+\"/\"+save_path+\"/\"+product+\".\"+signal_name+\".trend.pkl\")\n",
    "    elif reverse==-1: ## just reversal\n",
    "        save(reverse_signal_stat, HEAD_PATH+\"/\"+save_path+\"/\"+product+\".\"+signal_name+\".reverse.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get the statistics of backtesting a signal\n",
    "from collections import OrderedDict\n",
    "def get_signal_stat(signal_name, thre_mat, product, all_dates, CORE_NUM, split_str=\"2018\", reverse=1, \n",
    "                     atr_filter=0, HEAD_PATH=\"d:/intern\", SAVE_PATH=\"d:/intern\"):\n",
    "    train_sample = all_dates<split_str ## training samples\n",
    "    test_sample = all_dates>split_str ## testing samples\n",
    "    with dask.config.set(scheduler='processes', num_workers=CORE_NUM):\n",
    "        f_par = functools.partial(get_signal_pnl, product=product, signal_name=signal_name, thre_mat=thre_mat,\n",
    "                                 reverse=1,\n",
    "                                HEAD_PATH=HEAD_PATH, SAVE_PATH=SAVE_PATH,atr_filter=atr_filter)\n",
    "        train_result = compute([delayed(f_par)(file) for file in all_dates[train_sample]])[0] ## get training result\n",
    "    train_stat = get_hft_summary(train_result, thre_mat) ## get training result statistics\n",
    "    with dask.config.set(scheduler='processes', num_workers=CORE_NUM):\n",
    "        f_par = functools.partial(get_signal_pnl, product=product, signal_name=signal_name, thre_mat=thre_mat,\n",
    "                                 reverse=1,\n",
    "                                HEAD_PATH=HEAD_PATH, SAVE_PATH=SAVE_PATH,atr_filter=atr_filter)\n",
    "        test_result = compute([delayed(f_par)(file) for file in all_dates[test_sample]])[0] ## get testing result\n",
    "    test_stat = get_hft_summary(test_result, thre_mat) ## get testing result statistics\n",
    "    return OrderedDict([(\"train.stat\", train_stat), (\"test.stat\", test_stat)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(HEAD_PATH+\"/signal result atr/\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600519 nr\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "bad operand type for abs(): 'collections.OrderedDict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-29-90c071107070>\u001b[0m in \u001b[0;36mevaluate_signal\u001b[0;34m(signal, all_dates, product, min_pnl, min_num, CORE_NUM, HEAD_PATH, SIGNAL_PATH, period, split_str, atr_filter, save_path, reverse)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0msignal_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msignal\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mperiod\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m## signal name, with period\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mall_signal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSIGNAL_PATH\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/all signal/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mproduct\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0msignal_name\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".pkl\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m## get the distribution of the signal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mopen_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquantile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_signal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.991\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.999\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.9991\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.9999\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m## open threshold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mthre_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcartesian\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproduct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m## close threshold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: bad operand type for abs(): 'collections.OrderedDict'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#SIGNAL_PATH = \"e:/intern\"\n",
    "for product in product_list:\n",
    "    all_dates = np.array(os.listdir(DATA_PATH + product))\n",
    "    for signal in all_signal_list:\n",
    "        print(product, signal)\n",
    "        evaluate_signal(signal, all_dates, product, 0.001, 20, CORE_NUM, HEAD_PATH, SAVE_PATH,\n",
    "                        period=4096, split_str=\"2017\",\n",
    "            atr_filter=0.02, save_path=\"signal result atr\")\n",
    "\n",
    "## Wall time: 14h 53min 10s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- we can write a function to get all the signals' performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- we can get the result with atr and without atr separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get the signal performance\n",
    "## including trend and reverse signals\n",
    "def get_signal_performance_result(all_period_signal, signal_dire, period, product_list):\n",
    "    trend_signal_result = pd.DataFrame(data=OrderedDict([(\"signal\", all_period_signal), (\"reverse\",1),\n",
    "                               (\"num\", 0), (\"trainSharpe\", 0), (\"testSharpe\", 0)]))\n",
    "    reverse_signal_result = pd.DataFrame(data=OrderedDict([(\"signal\", all_period_signal), (\"reverse\",-1),\n",
    "                               (\"num\", 0), (\"trainSharpe\", 0), (\"testSharpe\", 0)]))\n",
    "    n_signal = len(all_period_signal) ## number of all signals\n",
    "    trend_train_sharpe = np.zeros(len(product_list))\n",
    "    trend_test_sharpe = np.zeros(len(product_list))\n",
    "    reverse_train_sharpe = np.zeros(len(product_list))\n",
    "    reverse_test_sharpe = np.zeros(len(product_list))\n",
    "    avg_pnl = 0.001\n",
    "    for k in range(n_signal):\n",
    "        signal_name = all_period_signal[k]\n",
    "        i = 0\n",
    "        for product in product_list:\n",
    "            all_dates = np.array(os.listdir(DATA_PATH + product))\n",
    "            train_sample = all_dates<\"2019\" \n",
    "            test_sample = all_dates>\"2019\"\n",
    "            stat_result = load(HEAD_PATH+\"/\" + signal_dire +\"/\"+product+\".\"+signal_name+\".pkl\") ## statistics of signal over a product\n",
    "            trend_signal_stat = stat_result['trend.signal.stat'] ## trending statistics\n",
    "            \n",
    "            if tuple(trend_signal_stat.keys())[0]=='train.stat':\n",
    "                train_stat = trend_signal_stat[\"train.stat\"]\n",
    "                test_stat = trend_signal_stat[\"test.stat\"]\n",
    "                #good_strat = trend_signal_stat[\"good.strat\"]\n",
    "                good_strat = (train_stat[\"final.result\"][\"avg.ret\"]>avg_pnl) & (train_stat[\"final.result\"][\"num\"]>10)\n",
    "                if sum(good_strat)>2:\n",
    "                    train_stat = trend_signal_stat[\"train.stat\"]\n",
    "                    test_stat = trend_signal_stat[\"test.stat\"]\n",
    "                    train_pnl = train_stat[\"daily.pnl\"][:, good_strat].sum(axis=1)/sum(good_strat)\n",
    "                    #train_std = np.std(train_pnl)\n",
    "                    #train_pnl = train_pnl/train_std\n",
    "                    test_pnl = test_stat[\"daily.pnl\"][:, good_strat].sum(axis=1)/sum(good_strat)\n",
    "                    trend_train_sharpe[i] = sharpe(train_pnl)\n",
    "                    trend_test_sharpe[i] = sharpe(test_pnl)\n",
    "                    #print(product, \"train sharpe \", sharpe(train_pnl), \"test sharpe \", sharpe(test_pnl))\n",
    "                    i = i+1\n",
    "            if i>0: ## if there are any good products\n",
    "                trend_signal_result.loc[k, (\"signal\", \"num\", \"trainSharpe\", \"testSharpe\")] = (signal_name, i,  np.mean(trend_train_sharpe[:i]),np.mean(trend_test_sharpe[:i]))\n",
    "        i = 0\n",
    "        for product in product_list:\n",
    "            stat_result = load(HEAD_PATH+\"/\"+signal_dire+\"/\"+product+\".\"+signal_name+\".pkl\")\n",
    "            reverse_signal_stat = stat_result['reverse.signal.stat']\n",
    "            if tuple(reverse_signal_stat.keys())[0]=='train.stat':\n",
    "                #good_strat = reverse_signal_stat[\"good.strat\"]\n",
    "                train_stat = reverse_signal_stat[\"train.stat\"]\n",
    "                train_pnl = train_stat[\"daily.pnl\"][:, good_strat].sum(axis=1)/sum(good_strat)\n",
    "                test_stat = reverse_signal_stat[\"test.stat\"]\n",
    "                good_strat = (train_stat[\"final.result\"][\"avg.ret\"]>avg_pnl) & (train_stat[\"final.result\"][\"num\"]>10)\n",
    "                test_pnl = test_stat[\"daily.pnl\"][:, good_strat].sum(axis=1)/sum(good_strat)\n",
    "                if sum(good_strat)>2:\n",
    "                    #train_std = np.std(train_pnl)\n",
    "                    #train_pnl = train_pnl/train_std\n",
    "                    reverse_train_sharpe[i] = sharpe(train_pnl)\n",
    "                    reverse_test_sharpe[i] = sharpe(test_pnl)\n",
    "                    i = i+1\n",
    "            if i>0:\n",
    "                \n",
    "                reverse_signal_result.loc[k, (\"signal\",\"num\", \"trainSharpe\", \"testSharpe\")] = (signal_name, i, np.mean(reverse_train_sharpe[:i]),np.mean(reverse_test_sharpe[:i]))\n",
    "    return OrderedDict([(\"trend.signal.stat\", trend_signal_result), \n",
    "                        (\"reverse.signal.stat\", reverse_signal_result)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_atr = get_signal_performance_result(all_period_signal, \"signal result atr\", 4096, product_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_single_signal_stat(result_atr, min_num=0, min_sharpe=0.5):\n",
    "    good_trend = (result_atr[\"trend.signal.stat\"][\"num\"]>min_num) & (result_atr[\"trend.signal.stat\"][\"trainSharpe\"]>min_sharpe) & (result_atr[\"trend.signal.stat\"][\"testSharpe\"]>min_sharpe)\n",
    "    good_reverse = (result_atr[\"reverse.signal.stat\"][\"num\"]>min_num) & (result_atr[\"reverse.signal.stat\"][\"trainSharpe\"]>min_sharpe) & (result_atr[\"reverse.signal.stat\"][\"testSharpe\"]>min_sharpe)\n",
    "    print(\"with atr good signals: \"+ str(sum(good_trend | good_reverse)))\n",
    "    train_sharpe = np.mean(np.append(result_atr[\"trend.signal.stat\"][\"trainSharpe\"][good_trend],\n",
    "                      result_atr[\"reverse.signal.stat\"][\"trainSharpe\"][good_reverse]))\n",
    "    test_sharpe = np.mean(np.append(result_atr[\"trend.signal.stat\"][\"testSharpe\"][good_trend],\n",
    "                      result_atr[\"reverse.signal.stat\"][\"testSharpe\"][good_reverse]))\n",
    "    print(\"train sharpe: \", train_sharpe)\n",
    "    print(\"test sharpe: \", test_sharpe)\n",
    "    print(all_signal_list[good_trend])\n",
    "    print(all_signal_list[good_reverse])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with atr good signals: 7\n",
      "train sharpe:  0.25031657008063096\n",
      "test sharpe:  0.3381809954027074\n",
      "['nr' 'price.osci' 'kdj.k' 'kdj.j' 'nr.trend.index'\n",
      " 'range.pos.trend.index' 'price.osci.trend.index']\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "get_single_signal_stat(result_atr, min_num=0, min_sharpe=0)\n",
    "\n",
    "# with atr good signals: 7\n",
    "# train sharpe:  0.25031657008063096\n",
    "# test sharpe:  0.3381809954027074\n",
    "# ['nr' 'price.osci' 'kdj.k' 'kdj.j' 'nr.trend.index'\n",
    "#  'range.pos.trend.index' 'price.osci.trend.index']\n",
    "# []\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with atr good signals: 6\n",
      "train sharpe:  0.232794205322825\n",
      "test sharpe:  0.335934275190708\n",
      "['nr' 'price.osci' 'kdj.k' 'nr.trend.index' 'range.pos.trend.index'\n",
      " 'price.osci.trend.index']\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "get_single_signal_stat(result_atr, min_num=1, min_sharpe=0)\n",
    "\n",
    "# with atr good signals: 6\n",
    "# train sharpe:  0.232794205322825\n",
    "# test sharpe:  0.335934275190708\n",
    "# ['nr' 'price.osci' 'kdj.k' 'nr.trend.index' 'range.pos.trend.index'\n",
    "#  'price.osci.trend.index']\n",
    "# []\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with atr good signals: 4\n",
      "train sharpe:  0.22417098533953134\n",
      "test sharpe:  0.2856700020721965\n",
      "['kdj.k' 'nr.trend.index' 'range.pos.trend.index' 'price.osci.trend.index']\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "get_single_signal_stat(result_atr, min_num=2, min_sharpe=0)\n",
    "\n",
    "# with atr good signals: 4\n",
    "# train sharpe:  0.22417098533953134\n",
    "# test sharpe:  0.2856700020721965\n",
    "# ['kdj.k' 'nr.trend.index' 'range.pos.trend.index' 'price.osci.trend.index']\n",
    "# []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with atr good signals: 1\n",
      "train sharpe:  0.21218760742128087\n",
      "test sharpe:  0.487643784373875\n",
      "['price.osci.trend.index']\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "get_single_signal_stat(result_atr, min_num=3, min_sharpe=0)\n",
    "\n",
    "# with atr good signals: 1\n",
    "# train sharpe:  0.21218760742128087\n",
    "# test sharpe:  0.487643784373875\n",
    "# ['price.osci.trend.index']\n",
    "# []\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with atr good signals: 1\n",
      "train sharpe:  0.21218760742128087\n",
      "test sharpe:  0.487643784373875\n",
      "['price.osci.trend.index']\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "get_single_signal_stat(result_atr, min_num=4, min_sharpe=0)\n",
    "\n",
    "# with atr good signals: 1\n",
    "# train sharpe:  0.21218760742128087\n",
    "# test sharpe:  0.487643784373875\n",
    "# ['price.osci.trend.index']\n",
    "# []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- we can see that their results are very similar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Conclusion\n",
    "- This week we have generated results for all of the 35 signals\n",
    "- We have compared backtest result with and without atr\n",
    "- we find that there is not much difference between them\n",
    "- previously we found that for iorn with atr is better than without atr\n",
    "- that's because we lower the threhsold for number of trades\n",
    "- now we use 20 trades for training maybe for i there are not enough trades\n",
    "- Anyway, currently there are too many signals and hard to tune parameters\n",
    "- in the future, we can use fewer signals so that we can do the research more efficiently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
